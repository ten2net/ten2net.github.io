<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>学习之心</title>
    <link>https://ten2net.github.io/index.xml</link>
    <description>Recent content on 学习之心</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <managingEditor>wangf@e-u.cn (wangf)</managingEditor>
    <webMaster>wangf@e-u.cn (wangf)</webMaster>
    <copyright>(c) 2017 ten2net 西安长城数字软件有限公司.</copyright>
    <lastBuildDate>Thu, 22 Dec 2016 12:59:30 +0800</lastBuildDate>
    <atom:link href="https://ten2net.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>使用Pandoc工具转换ms word文件为Markdown格式</title>
      <link>https://ten2net.github.io/2016/12/22/%E4%BD%BF%E7%94%A8pandoc%E5%B7%A5%E5%85%B7%E8%BD%AC%E6%8D%A2ms-word%E6%96%87%E4%BB%B6%E4%B8%BAmarkdown%E6%A0%BC%E5%BC%8F/</link>
      <pubDate>Thu, 22 Dec 2016 12:59:30 +0800</pubDate>
      <author>wangf@e-u.cn (wangf)</author>
      <guid>https://ten2net.github.io/2016/12/22/%E4%BD%BF%E7%94%A8pandoc%E5%B7%A5%E5%85%B7%E8%BD%AC%E6%8D%A2ms-word%E6%96%87%E4%BB%B6%E4%B8%BAmarkdown%E6%A0%BC%E5%BC%8F/</guid>
      <description>

&lt;h1 id=&#34;markdown-pandoc-最佳写作拍档&#34;&gt;Markdown+Pandoc 最佳写作拍档&lt;/h1&gt;

&lt;p&gt;###我们为什么写作？
自从人们开始写作，写作便是记录、抒发、批判、反省的好工具。从石板上的刻印到笔墨纸砚，再到如今的信息时代。从静态的个人主页到托管博客，从个人博客到微博，从wordpress到jekyll。无数投入写作中的人们写作的目的大同，写作的方式越简单越好，这样才能让我们专注于写作而不是为其他格式所困扰。另外现在智能终端快速普及，文件格式的多平台使用也成为了写作的一大问题。&lt;/p&gt;

&lt;p&gt;为了更好的写作,今天介绍的 Markdown &amp;amp; Pandoc 便能提供完美的辅助。&lt;/p&gt;

&lt;p&gt;###Markdown的用法&lt;/p&gt;

&lt;p&gt;####1 .Markdown是什么?&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Markdown 是一种轻量级标记语言，创始人为John Gruber和Aaron Swartz。它允许人们“使用易读易写的纯文本格式编写文档，然后转换成有效的XHTML(或者HTML)文档”。这种语言吸收了很多在电子邮件中已有的纯文本标记的特性。 &lt;a href=&#34;https://zh.wikipedia.org/wiki/Markdown&#34;&gt;[1]&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;####2 .为什么要用Markdown?&lt;/p&gt;

&lt;p&gt;windows下常用的编辑工具是word,mac上常用的编辑工具是page,linux上常用的编辑工具就是vim了，一份文章编辑完后为了要在不同平台中保存完整的模样时就必需同时准备多种文本格式的文件，这是多么痛苦的一件事。我们写作的初衷是为了写作呀，反而被这些格式烦恼。所以我们要用Markdown,它让你关注内容，格式怎么显示不是要你在写得时候关注的。而在写Markdown时你只需要用一个纯文本的方式进行，不用担心平台与格式的困扰。&lt;/p&gt;

&lt;p&gt;####3 .Markdown的语法&lt;/p&gt;

&lt;p&gt;Markdown 的语法全由一些符号所组成，这些符号经过精挑细选，其作用一目了然。比如：在文字两旁加上星号，看起来就像*强调*。Markdown 的列表看起来，嗯，就是列表。Markdown 的区块引用看起来就真的像是引用一段文字，就像你曾在电子邮件中见过的那样。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;最常用格式&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; 空一行（两个回车）分段
 行末加两个或多个空格才是真正的换行，否则正常的一个回车就像在 HTML 代码中一样，被当作空格处理
 插入链接：  [链接文字](url) 
 图片跟链接很像，在前面加个叹号：![alt 文字](图片 URL)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;列表&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;* 无序(没有编号的)列表中的一项
* 一个子项，要以一个制表符或者4个空格缩进
* 无序列表中的另一个项
1. 有序(排好序，有编号的)列表中的一项
2. 有序列表中的另一个项
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;标题&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 一级标题

#### 四级标题

一级标题
===================

二级标题
--------------------
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;代码&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;代码可以采取两种方法：&lt;/p&gt;

&lt;p&gt;一是用（`）将代码包起来&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;夹杂着`一些代码`的文字内容,
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;二是在代码块前面加上4个空格或者一个TAB&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    import random

    class CardGame(object):
        &amp;quot;&amp;quot;&amp;quot; a sample python class &amp;quot;&amp;quot;&amp;quot;
        NB_CARDS = 32
        def __init__(self, cards=5):
            self.cards = random.sample(range(self.NB_CARDS), 5)
            print &#39;ready to play&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;代码高亮可以由github提供的js实现&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;分割线&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;要生成水平分割线，可以在单独一行里输入3个或以上的短横线、星号或者下划线实现。短横线和星号之间可以输入任意空格。以下每一行都产生一条水平分割线。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;===========
************
_ _ _ _ _
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Markdown的常用语法差不多就是这些了，详细的介绍请参考&lt;a href=&#34;http://wowubuntu.com/markdown/&#34;&gt;Markdowm 语法说明&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;####4 .Markdown的常用编辑工具&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Mac等平台下推荐&lt;a href=&#34;http://mouapp.com/&#34;&gt;Mou&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Windows平台推荐&lt;a href=&#34;http://markdownpad.com/&#34;&gt;MarkdownPad&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.sublimetext.com/&#34;&gt;Sublime Text&lt;/a&gt;编辑器是我的最爱，并且它是跨平台的，结合&lt;a href=&#34;https://github.com/revolunet/sublimetext-markdown-preview&#34;&gt;Markdown preview&lt;/a&gt;插件能更好的编辑&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/adam-p/markdown-here&#34;&gt;markdown-here&lt;/a&gt;借助Chrome插件，将gmail、Evernote、Hotmail等写作窗口变为Markdown在线写作窗口&lt;/li&gt;
&lt;li&gt;web版推荐国人&lt;a href=&#34;http://jser.me/&#34;&gt;草依山&lt;/a&gt;写的&lt;a href=&#34;http://mahua.jser.me&#34;&gt;MaHua&lt;/a&gt;,支持vim快捷键和多种主题。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Markdown越来越流行，不是因为它复杂，而是因为它足够简单。尝试过MD后就能体会到单纯的写作带来的快乐，一般Markdown文件保存格式都是以md、mdownx现实。为了文档的分享,多平台的使用，需要对MD进行格式转化。这是就更体现了它的方便之处，它是本身是一个结构标记语言，能对多种格式文档进行转换，这里介绍一款强大的格式转换工具 &lt;strong&gt;Pandoc&lt;/strong&gt; 。&lt;/p&gt;

&lt;p&gt;###Pandoc 格式转换的瑞士军刀&lt;/p&gt;

&lt;p&gt;####1 .Pandoc的介绍&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Pandoc是一个用于从一种标记格式转换为另一种的Haskell库，它的功能是在多种常见的标记语言进行相互转换。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;其中包括 Markdown, reStructuredText, Textilte, HTML, PDF,LaTeX 等。利用它，你可以用简单的 Markdown 语法生成pdf文档，还可以写 Beamer 演示文稿。更强大的是，它还能将以上提到的这些语言所写文件转换成 xdoc 文档。下面这张图展示了 Pandoc 让人吃惊 的功能集，不愧为文件转换中的瑞士军刀：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://iout.in/demo/pic/pandoc.jpg&#34; alt=&#34; pandoc &#34; /&gt;&lt;/p&gt;

&lt;p&gt;####2 .Pandoc的用法&lt;/p&gt;

&lt;p&gt;#####2.1 Web版Pandoc
首先我们可以看下Pandoc的官网 &lt;a href=&#34;http://johnmacfarlane.net/pandoc/&#34;&gt;http://johnmacfarlane.net/pandoc/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;在介绍中我们知道Pandoc支持linux,Mac OS,Win多平台，还有简易的web版提供我们在线转换格式。打开web版 &lt;a href=&#34;http://johnmacfarlane.net/pandoc/try&#34;&gt;http://johnmacfarlane.net/pandoc/try&lt;/a&gt;,便可以进行简单的格式转换了。不过网页版的反应速度不是很快，不适合大型文件的格式转换，一两篇文章还是可以的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://iout.in/demo/pic/webpandoc.png&#34; alt=&#34;webpandoc&#34; /&gt;&lt;/p&gt;

&lt;p&gt;#####2.2 Linux版Pandoc
就我自己用的ubuntu下安装Pandoc,还算是非常简单的。以下是ubuntu下的使用步骤:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get install pandoc
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果apt-get安装的pandoc功能不齐全，可以如官网上一样先安装cable,再安装pandoc:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get install cabal-install
cabal update
cabal install pandoc
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后就可以尝试着用一下了：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pandoc demo.md -o demo.html
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样便可以简单的将demo的markdown文件转换成html文档了。另外还可以强制格式转换如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pandoc demo.txt -o demo.html -f markdown -t html
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面的代码便是将demo.txt中的文档以markdown的格式转换成html并存入demo.html中了。&lt;/p&gt;

&lt;p&gt;最关键的 &lt;strong&gt;PDF文件&lt;/strong&gt; 到了，PDF文档能在不同平台保持一致的表现，是许多文档传输的首选。在转换PDF之前,还需要安装一个texlive的包：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; sodu apt-get install texlive
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后便可以自如的转换PDF文件了：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pandoc demo.md -o demo.pdf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;英文文件转换状况良好，中文字体问题请参考&lt;a href=&#34;http://www.openfoundry.org/tw/foss-programs/8814-pandoc-&#34;&gt;Pandoc 用命令行转换标记语言&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Markdown与Pandoc的用法也就说到这了，无疑它们搭配起来会让写作变得更加简单专注，这也就是我们的初衷。另外在写作中多结合Git,将文档推到GitHub上会是很好的尝试。&lt;/p&gt;

&lt;p&gt;#####参考文档
+ &lt;a href=&#34;http://www.yangzhiping.com/tech/r-markdown-knitr.html&#34;&gt;Markdown写作浅谈&lt;/a&gt; , 阳志平
+ &lt;a href=&#34;http://yanping.me/cn/blog/2012/03/13/pandoc/&#34;&gt;黑魔法利器pandoc&lt;/a&gt; , 雁起平沙
+ &lt;a href=&#34;http://www.openfoundry.org/tw/foss-programs/8814-pandoc-&#34;&gt;Pandoc 用命令行转换标记语言&lt;/a&gt; , 林雪凡
+ &lt;a href=&#34;http://johnmacfarlane.net/pandoc&#34;&gt;Pandoc 官网&lt;/a&gt; , John MacFarlane
+ &lt;a href=&#34;http://wowubuntu.com/markdown/&#34;&gt;Markdown 语法说明&lt;/a&gt; , riku&lt;/p&gt;

&lt;p&gt;&lt;code&gt;tag&lt;/code&gt;: markdown,pandoc&lt;/p&gt;

&lt;p&gt;&lt;code&gt;author&lt;/code&gt;：lv&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>使用jupyter nbconvert转换jupyter notebook笔记为Markdown格式</title>
      <link>https://ten2net.github.io/2016/12/22/%E4%BD%BF%E7%94%A8jupyter-nbconvert%E8%BD%AC%E6%8D%A2jupyter-notebook%E7%AC%94%E8%AE%B0%E4%B8%BAmarkdown%E6%A0%BC%E5%BC%8F/</link>
      <pubDate>Thu, 22 Dec 2016 12:59:11 +0800</pubDate>
      <author>wangf@e-u.cn (wangf)</author>
      <guid>https://ten2net.github.io/2016/12/22/%E4%BD%BF%E7%94%A8jupyter-nbconvert%E8%BD%AC%E6%8D%A2jupyter-notebook%E7%AC%94%E8%AE%B0%E4%B8%BAmarkdown%E6%A0%BC%E5%BC%8F/</guid>
      <description>

&lt;h1 id=&#34;nbconvert&#34;&gt;nbconvert&lt;/h1&gt;

&lt;h3 id=&#34;jupyter-notebook-conversion&#34;&gt;Jupyter Notebook Conversion&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://groups.google.com/forum/#!forum/jupyter&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-Google%20Group-lightgrey.svg&#34; alt=&#34;Google Group&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;https://travis-ci.org/jupyter/nbconvert&#34;&gt;&lt;img src=&#34;https://travis-ci.org/jupyter/nbconvert.svg?branch=master&#34; alt=&#34;Build Status&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;https://nbconvert.readthedocs.io/en/latest/?badge=latest&#34;&gt;&lt;img src=&#34;https://readthedocs.org/projects/nbconvert/badge/?version=latest&#34; alt=&#34;Documentation Status&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;http://nbconvert.readthedocs.io/en/stable/?badge=stable&#34;&gt;&lt;img src=&#34;https://readthedocs.org/projects/nbconvert/badge/?version=stable&#34; alt=&#34;Documentation Status&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;https://codecov.io/github/jupyter/nbconvert?branch=master&#34;&gt;&lt;img src=&#34;https://codecov.io/github/jupyter/nbconvert/coverage.svg?branch=master&#34; alt=&#34;codecov.io&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;用法&#34;&gt;用法&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;    $ jupyter nbconvert --to &amp;lt;output format&amp;gt; &amp;lt;input notebook&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;其中：&lt;output format&gt;`可以是下面几种：&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;-* HTML
-* LaTeX
-* PDF
-* Reveal JS
-* Markdown (md)
-* ReStructured Text (rst)
-* executable script&lt;/p&gt;

&lt;h3 id=&#34;例子-convert-a-notebook-to-html&#34;&gt;例子: Convert a notebook to HTML&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;    $ jupyter nbconvert --to html mynotebook.ipynb
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This command creates an HTML output file named &lt;code&gt;mynotebook.html&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;资源&#34;&gt;资源&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://nbconvert.readthedocs.io/en/latest/&#34;&gt;Documentation for Jupyter nbconvert&lt;/a&gt;
[&lt;a href=&#34;https://media.readthedocs.org/pdf/nbconvert/latest/nbconvert.pdf&#34;&gt;PDF&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/jupyter/nbconvert-examples&#34;&gt;nbconvert examples on GitHub&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/jupyter/nbconvert/issues&#34;&gt;Issues&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://groups.google.com/forum/#!forum/jupyter&#34;&gt;Technical support - Jupyter Google Group&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jupyter.org&#34;&gt;Project Jupyter website&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jupyter.readthedocs.io/en/latest/index.html&#34;&gt;Documentation for Project Jupyter&lt;/a&gt;
[&lt;a href=&#34;https://media.readthedocs.org/pdf/jupyter/latest/jupyter.pdf&#34;&gt;PDF&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>计算机三维仿真常用软件</title>
      <link>https://ten2net.github.io/2016/12/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%89%E7%BB%B4%E4%BB%BF%E7%9C%9F%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6/</link>
      <pubDate>Thu, 22 Dec 2016 12:12:19 +0800</pubDate>
      <author>wangf@e-u.cn (wangf)</author>
      <guid>https://ten2net.github.io/2016/12/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%89%E7%BB%B4%E4%BB%BF%E7%9C%9F%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6/</guid>
      <description>

&lt;ol&gt;
&lt;li&gt;地图绘制及地形数据处理软件：Global Mapper 16&lt;/li&gt;

&lt;li&gt;&lt;h2 id=&#34;三维交互电子手册制作软件-eon-professional-9-0&#34;&gt;三维交互电子手册制作软件 EON Professional 9.0&lt;/h2&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;加拿大Presagis公司 三维建模软件：Creator 4.2&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;加拿大Presagis公司 地形建模软件：Terra Vista 6.2&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;加拿大Presagis公司 视景仿真软件：Vega Prime 4.1 for VC8&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;h2 id=&#34;美国disti公司-虚拟仪表仿真软件-gl-studio-3-2-for-vc8&#34;&gt;美国DiSTI公司 虚拟仪表仿真软件:GL Studio 3.2  for VC8&lt;/h2&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;美国MAK公司 计算机兵力生成及军事想定编辑与仿真软件：MAK VR_FORCE 3.12.0.2&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;美国MAK公司 实时系统运行支撑软件：MAK_RTI 3.4&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;美国MAK公司 分布式仿真连接软件开发包：VR_LINK 3.11.1&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;美国MAK公司 三维战场态势软件：MAK stealth 6.2 、VR_VANTAGE 1.2.1&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>我的docker笔记</title>
      <link>https://ten2net.github.io/2016/12/22/%E6%88%91%E7%9A%84docker%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Thu, 22 Dec 2016 11:15:53 +0800</pubDate>
      <author>wangf@e-u.cn (wangf)</author>
      <guid>https://ten2net.github.io/2016/12/22/%E6%88%91%E7%9A%84docker%E7%AC%94%E8%AE%B0/</guid>
      <description>

&lt;h1 id=&#34;1-docker命令基础练习&#34;&gt;1 Docker命令基础练习&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker info
docker images
docker ps
docker version
docker run hello-world
docker pull busybox
docker exec -it busybox /bin/bash

docker run -d -p 80:80 --name webserver nginx
docker run -it alpine env
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;2-dockerfile使用范例&#34;&gt;2 Dockerfile使用范例&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;FROM tomcat
ADD helloworld.war /usr/local/tomcat/webapps/
EXPOSE 8080
CMD [&amp;quot;catalina.sh&amp;quot;, &amp;quot;run&amp;quot;]


docker build -t mytomcat .
docker run -d -p 9280:8080 mytomcat2
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;3-使用-docker-7-个命令部署一个-mesos-集群&#34;&gt;3 使用 Docker， 7 个命令部署一个 Mesos 集群&lt;/h1&gt;

&lt;p&gt;参考：&lt;a href=&#34;https://segmentfault.com/a/1190000002531072&#34;&gt;https://segmentfault.com/a/1190000002531072&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
第一步：或者 Docker 服务器的 IP 并导出到环境变量。我们将在随后的 Docker 命令中不断地使用这个 IP。
set HOST_IP=10.11.31.7
第二步：启动 ZooKeeper 容器
docker run -d -p 2181:2181 -p 2888:2888 -p 3888:3888 garland/zookeeper
第三步：启动 Mesos Master
docker run --net=&amp;quot;host&amp;quot; -p 5050:5050 -e &amp;quot;MESOS_HOSTNAME=${HOST_IP}&amp;quot; -e &amp;quot;MESOS_IP=${HOST_IP}&amp;quot; -e &amp;quot;MESOS_ZK=zk://${HOST_IP}:2181/mesos&amp;quot; -e &amp;quot;MESOS_PORT=5050&amp;quot; -e &amp;quot;MESOS_LOG_DIR=/var/log/mesos&amp;quot; -e &amp;quot;MESOS_QUORUM=1&amp;quot; -e &amp;quot;MESOS_REGISTRY=in_memory&amp;quot; -e &amp;quot;MESOS_WORK_DIR=/var/lib/mesos&amp;quot; -d garland/mesosphere-docker-mesos-master
第四步：启动 Marathon
docker run -d -p 8180:8180 garland/mesosphere-docker-marathon --master zk://${HOST_IP}:2181/mesos --zk zk://${HOST_IP}:2181/marathon
第五步：在一个容器中启动 Mesos Slave
docker run -d --name mesos_slave_1 --entrypoint=&amp;quot;mesos-slave&amp;quot; -e &amp;quot;MESOS_MASTER=zk://${HOST_IP}:2181/mesos&amp;quot; -e &amp;quot;MESOS_LOG_DIR=/var/log/mesos&amp;quot; -e &amp;quot;MESOS_LOGGING_LEVEL=INFO&amp;quot; garland/mesosphere-docker-mesos-master:latest
第六步：进入 Mesos 的 webpage
http://${HOST_IP}:5050
第七步：进入 Marathon 的 webpage 启动一个任务
http://${HOST_IP}:8080
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;4-使用docker-加速器&#34;&gt;4 使用Docker 加速器&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;echo &amp;quot;DOCKER_OPTS=\&amp;quot;\$DOCKER_OPTS --registry-mirror=https://z5sa40yd.mirror.aliyuncs.com\&amp;quot;&amp;quot; | sudo tee -a /etc/default/docker sudo service docker restart
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;阿里云-我的专属加速器地址：&lt;a href=&#34;https://z5sa40yd.mirror.aliyuncs.com&#34;&gt;https://z5sa40yd.mirror.aliyuncs.com&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;这个命令的用法忘记了&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker-machine create --virtualbox-no-vtx-check --engine-registry-mirror=https://z5sa40yd.mirror.aliyuncs.com -d virtualbox default
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;5-ui-for-docker-可视化管理docker的工具&#34;&gt;5 ui-for-docker，可视化管理Docker的工具&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Quickstart ：&lt;a href=&#34;https://github.com/kevana/ui-for-docker&#34;&gt;https://github.com/kevana/ui-for-docker&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt; docker run -d -p 9000:9000 --privileged -v /var/run/docker.sock:/var/run/docker.sock uifd/ui-for-docker
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Open your browser to http://&lt;your Host IP&gt;:9000&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;6-docker-run-命令的常用选项说明&#34;&gt;6 Docker Run 命令的常用选项说明&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;你的Container会在你结束命令之后自动退出，使用以下的命令选项可以将容器保持在激活状态：&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;-i 即使在没有附着的情况下依然保持STDIN处于开启
-t 分配一个伪TTY控制台&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;所以run命令就变成了：
&lt;code&gt;
docker run -it -d shykes/pybuilder bin/bash
&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Docker Exec 命令可以执行正在运行的Docker容器中的Shell命令&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;如果希望能够附着到一个已经存在的容器中，则利用exec命令：&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;docker exec -it CONTAINER_ID bash
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;7-常见的docker命令行命令进行详细介绍&#34;&gt;7 常见的Docker命令行命令进行详细介绍&lt;/h1&gt;

&lt;h2 id=&#34;7-1-与容器-container-相关的命令&#34;&gt;7.1 与容器（Container）相关的命令&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;docker create 会创建一个容器但是不会立刻启动&lt;/li&gt;
&lt;li&gt;docker run 会创建并且启动某个容器&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果只是希望有一个暂时性的容器，可以使用 docker run &amp;ndash;rm 将会在容器运行完毕之后删除该容器。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果希望在打开某个容器之后能够与其进行交互, docker run -t -i  会创建一个TTY控制台。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;docker stop 会关闭某个容器&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;docker start 会启动某个容器&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;docker restart 会重新启动某个容器&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;docker rm 会删除某个容器&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果希望能够移除所有与该容器相关的Volume，可以使用-v参数： docker rm -v.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;docker kill 会发送SIGKILL信号量到某个容器&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;docker attach 会附着到某个正在运行的容器&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;docker wait 会阻塞直到某个容器关闭&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;7-2-与镜像-image-相关的命令&#34;&gt;7.2 与镜像（Image）相关的命令&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;docker images 会展示所有的镜像&lt;/li&gt;
&lt;li&gt;docker import 会从原始码中创建镜像&lt;/li&gt;
&lt;li&gt;docker build 会从某个Dockfile中创建镜像&lt;/li&gt;
&lt;li&gt;docker commit 会从某个Container中创建镜像&lt;/li&gt;
&lt;li&gt;docker rmi 会移除某个镜像&lt;/li&gt;
&lt;li&gt;docker load 以STDIN的方式从某个tar包中加载镜像&lt;/li&gt;
&lt;li&gt;docker save 以STDOUT的方式将镜像存入到某个tar包中&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;7-3-查看docker容器状态信息的命令&#34;&gt;7.3 查看Docker容器状态信息的命令&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;docker ps 会列举出所有正在运行的容器&lt;/li&gt;
&lt;li&gt;docker ps -a 会展示出所有正在运行的和已经停止的容器&lt;/li&gt;
&lt;li&gt;docker logs 从某个容器中获取log日志&lt;/li&gt;
&lt;li&gt;docker inspect 检测关于某个容器的详细信息&lt;/li&gt;
&lt;li&gt;docker events 从某个容器中获取所有的事件&lt;/li&gt;
&lt;li&gt;docker port 获取某个容器的全部的开放端口&lt;/li&gt;
&lt;li&gt;docker top 展示某个容器中运行的全部的进程&lt;/li&gt;
&lt;li&gt;docker stats 展示某个容器中的资源的使用情况的统计信息&lt;/li&gt;
&lt;li&gt;docker diff 展示容器中文件的变化情况&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;7-4-查看docker镜像-image-状态信息的命令&#34;&gt;7.4 查看Docker镜像（Image）状态信息的命令&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;docker history 展示镜像的全部历史信息&lt;/li&gt;
&lt;li&gt;docker tag 为某个容器设置标签&lt;/li&gt;
&lt;li&gt;Import&amp;amp;Export&lt;/li&gt;
&lt;li&gt;docker cp 在容器与本地文件系统之间进行文件复制&lt;/li&gt;
&lt;li&gt;docker export 将某个容器中的文件系统的内容输出到某个tar文件中&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;8-实验machine-learning-过程中练习的命令&#34;&gt;8 实验Machine Learning 过程中练习的命令&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;docker run  ermaker/keras&lt;/li&gt;

&lt;li&gt;&lt;p&gt;docker run -d -p 8888:8888 -e KERAS_BACKEND=tensorflow ermaker/keras-jupyter&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;docker run -d -p 8888:8888 &amp;ndash;name keraslearning  &amp;ndash;restart=always  -v /notebook:/notebook ermaker/keras-jupyter&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;docker run -d -p 8888:8888 &amp;ndash;name keraslearning   &amp;ndash;restart=always -v E:/python-dev-home:/notebook ermaker/keras-jupyter&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;docker run -d -p 8888:8888 &amp;ndash;name keraslearning &amp;ndash;restart=always -v E:/python-dev-home:/notebook ermaker/keras-jupyter&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;nvidia-docker run  -d -p 5001:5000 -v /dataOne:/opt &amp;ndash;name digits &amp;ndash;restart=always  kaixhin/cuda-digits:8.0&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;9-其它常用命令&#34;&gt;9 其它常用命令&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;    # 像Docker官方的hello world例子一样，拉取一个叫busybox的镜像
    docker pull busybox
    
    #进入容器bash
    docker exec -i keraslearning bash

    # 查看本地已经有哪些镜像
    # 我们可以看到busybox
    docker images

    # 现在让我们来修改下busybox镜像的容器
    # 这次，我们创建一个文件夹
    docker run busybox mkdir /home/test


    #从容器keraslearning中复制/notebook目录到当前目录
    docker cp keraslearning:/notebook .

    #从当前目录复制test子目录到容器keraslearning中/notebook目录下
    docker cp test keraslearning:/notebook

    # 让我们再看看我们有哪些镜像了。
    # 注意每条命令执行后容器都会停止
    # 可以看到有一个busybox容器
    docker ps -a

    # 现在，可以提交修改了。
    # 提交后会看到一个新的镜像busybox-1
    #  &amp;lt;CONTAINER ID&amp;gt; 是刚刚修改容器后得到的ID
    docker commit &amp;lt;CONTAINER ID&amp;gt; busybox-1

    # 再看看我们有哪些镜像。
    # 我们现在同时有busybox和busybox-1镜像了。
    docker images

    # 我们执行以下命令，看看这两个镜像有什么不同
    docker run busybox [ -d /home/test ] &amp;amp;&amp;amp; echo &#39;Directory found&#39; || echo &#39;Directory not found&#39;
    docker run busybox-1 [ -d /home/test ] &amp;amp;&amp;amp; echo &#39;Directory found&#39; || echo &#39;Directory not found&#39;


    # 查看所有的容器
    docker ps -a

    # 删除它们
    docker rm &amp;lt;CONTAINER ID&amp;gt;

    # 查看所有的镜像
    docker images

    # 删除它们
    docker rmi busybox-1
    docker rmi busybox

    注：可以使用 docker rm $(docker ps -q -a) 一次性删除所有的容器，docker rmi $(docker images -q) 一次性删除所有的镜像。

    #导出容器
    docker export &amp;lt;CONTAINER ID&amp;gt; -o containers/export123.tar

    #导出镜像
    docker save -o gds-keras-jupyter.tar gds/keraslearning

    #快照容器的当前状态为一个镜像
    docker commit 0d8facbc75e2 gds/keraslearning


    现在我们创建了两个Tar文件，让我们来看看它们是什么。首先做一下小清理——把所有的容器和镜像都删除：

    # 查看所有的容器
    sudo docker ps -a

    # 删除它们
    sudo docker rm &amp;lt;CONTAINER ID&amp;gt;

    # 查看所有的镜像
    sudo docker images

    # 删除它们
    sudo docker rmi busybox-1
    sudo docker rmi busybox
    注：可以使用 docker rm $(docker ps -q -a) 一次性删除所有的容器，docker rmi $(docker images -q) 一次性删除所有的镜像。

    现在开始导入刚刚导出的容器：

    # 导入export.tar文件
    cat /home/export.tar | sudo docker import - busybox-1-export:latest

    # 查看镜像
    sudo docker images

    # 检查是否导入成功，就是启动一个新容器，检查里面是否存在/home/test目录（是存在的）
    sudo docker run busybox-1-export [ -d /home/test ] &amp;amp;&amp;amp; echo &#39;Directory found&#39; || echo &#39;Directory not found&#39;
    使用类似的步骤导入镜像：

    # 导入save.tar文件
    docker load &amp;lt; /home/save.tar
    docker load -i /home/save.tar

    # 查看镜像
    sudo docker images

    # 检查是否导入成功，就是启动一个新容器，检查里面是否存在/home/test目录（是存在的）
    sudo docker run busybox-1 [ -d /home/test ] &amp;amp;&amp;amp; echo &#39;Directory found&#39; || echo &#39;Directory not found&#39;
    那，它们之间到底存在什么不同呢？我们发现导出后的版本会比原来的版本稍微小一些。那是因为导出后，会丢失历史和元数据。执行下面的命令就知道了：

    # 显示镜像的所有层(layer)
    sudo docker images --tree
     执行命令，显示下面的内容。正你看到的，导出后再导入(exported-imported)的镜像会丢失所有的历史，而保存后再加载（saveed-loaded）的镜像没有丢失历史和层(layer)。这意味着使用导出后再导入的方式，你将无法回滚到之前的层(layer)，同时，使用保存后再加载的方式持久化整个镜像，就可以做到层回滚（可以执行docker tag &amp;lt;LAYER ID&amp;gt; &amp;lt;IMAGE NAME&amp;gt;来回滚之前的层）。

    sudo docker images --tree
    ├─f502877df6a1 Virtual Size: 2.489 MB Tags: busybox-1-export:latest
    └─511136ea3c5a Virtual Size: 0 B
      └─bf747efa0e2f Virtual Size: 0 B
        └─48e5f45168b9 Virtual Size: 2.489 MB
          └─769b9341d937 Virtual Size: 2.489 MB
            └─227516d93162 Virtual Size: 2.489 MB Tags: busybox-1:latest

&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>深度学习库Keras快速入门笔记</title>
      <link>https://ten2net.github.io/2016/12/22/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BA%93keras%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Thu, 22 Dec 2016 11:15:53 +0800</pubDate>
      <author>wangf@e-u.cn (wangf)</author>
      <guid>https://ten2net.github.io/2016/12/22/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BA%93keras%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/</guid>
      <description>

&lt;h1 id=&#34;如何开始&#34;&gt;如何开始&lt;/h1&gt;

&lt;h2 id=&#34;1-光标移动到下面的-import-keras-cell中&#34;&gt;1、光标移动到下面的 import keras   Cell中；&lt;/h2&gt;

&lt;h2 id=&#34;2-shift-enter或点击上面的运行按钮-类似播放&#34;&gt;2、Shift+Enter或点击上面的运行按钮（类似播放）&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;  出现Using Theano backend.那么Keras就已经成功安装了
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import keras
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#查看mnist数据集
%matplotlib inline
from keras.datasets import mnist
from matplotlib import pyplot as plt
# load data
(X_train, y_train), (X_test, y_test) = mnist.load_data(&amp;quot;/notebook/datasets/mnist.pkl&amp;quot;)
# create a grid of 3x3 images
for i in range(0, 9):
    plt.subplot(330 + 1 + i)
    plt.imshow(X_train[i], cmap=plt.get_cmap(&#39;gray&#39;))
# show the plot
plt.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
from matplotlib import pyplot as plt

from keras.models import Sequential
from keras.layers import Dense,Dropout
from keras.models import model_from_json
import numpy
import os
# 为了多次执行再现结果，这只一个固定的随机数   fix random seed for reproducibility
seed = 7
numpy.random.seed(seed)
# 加载数据集 load pima indians dataset
dataset = numpy.loadtxt(&amp;quot;pima-indians-diabetes.csv&amp;quot;, delimiter=&amp;quot;,&amp;quot;)
# 分开数据集为输入和输出两部分  split into input (X) and output (Y) variables
X = dataset[:,0:8]
Y = dataset[:,8]

print (X.shape,Y.shape)
print (Y)

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;(768, 8) (768,)
[ 1.  0.  1.  0.  1.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  1.  1.  1.
  0.  1.  0.  0.  1.  1.  1.  1.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.
  0.  1.  1.  1.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.
  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.
  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1.  1.  1.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.  0.  0.  1.  1.
  0.  0.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.
  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  0.  0.
  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  1.  0.  1.
  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  1.  1.  0.  1.  0.  1.
  1.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  1.  1.  1.
  1.  0.  1.  1.  1.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.
  0.  1.  1.  1.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.  0.  0.
  0.  0.  1.  1.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.  1.  0.  0.  1.
  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.
  0.  0.  0.  1.  1.  1.  0.  0.  1.  0.  1.  0.  1.  1.  0.  1.  0.  0.
  1.  0.  1.  1.  0.  0.  1.  0.  1.  0.  0.  1.  0.  1.  0.  1.  1.  1.
  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.
  1.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.
  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  1.  0.  1.  1.  0.  1.  0.  1.  0.  1.  0.  1.  1.  0.  0.  0.  0.
  1.  1.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  0.
  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  1.  0.
  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  1.
  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.
  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.
  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.
  1.  1.  1.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.
  0.  1.  0.  1.  1.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  0.  1.  0.
  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.  1.
  1.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  1.
  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.
  1.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.  1.
  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  1.  0.  0.  0.  0.  1.
  1.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.
  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.
  0.  1.  1.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  1.  0.  1.  0.  1.  0.  0.  0.  0.  1.  0.]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
from matplotlib import pyplot as plt

from keras.models import Sequential
from keras.layers import Dense,Dropout
from keras.models import model_from_json
import numpy
import os
# 为了多次执行再现结果，这只一个固定的随机数   fix random seed for reproducibility
seed = 7
numpy.random.seed(seed)
# 加载数据集 load pima indians dataset
dataset = numpy.loadtxt(&amp;quot;pima-indians-diabetes.csv&amp;quot;, delimiter=&amp;quot;,&amp;quot;)
# 分开数据集为输入和输出两部分  split into input (X) and output (Y) variables
X = dataset[:,0:8]
Y = dataset[:,8]

# 创建模型 create model
model = Sequential()
model.add(Dense(12, input_dim=8, init=&#39;uniform&#39;, activation=&#39;relu&#39;))
model.add(Dense(8, init=&#39;uniform&#39;, activation=&#39;relu&#39;))
model.add(Dense(1, init=&#39;uniform&#39;, activation=&#39;sigmoid&#39;))
# 编译模型 Compile model
model.compile(loss=&#39;binary_crossentropy&#39;, optimizer=&#39;adam&#39;, metrics=[&#39;accuracy&#39;])
# 训练模型  Fit the model
history= model.fit(X, Y,validation_split=0.25, nb_epoch=300, batch_size=10, verbose=0)

# 评估模型 evaluate the model
scores = model.evaluate(X, Y, verbose=0)
print(&amp;quot;%s: %.2f%%&amp;quot; % (model.metrics_names[1], scores[1]*100))
 
# 保存模型 serialize model to JSON
model_json = model.to_json()
with open(&amp;quot;./models/diabetes-model.json&amp;quot;, &amp;quot;w&amp;quot;) as json_file:
    json_file.write(model_json)
# 保存权重 serialize weights to HDF5
model.save_weights(&amp;quot;./models/diabetes-model.h5&amp;quot;)
print(&amp;quot;Saved model to disk&amp;quot;)

#训练过程可视化
# list all data in history
print(history.history.keys())
# summarize history for accuracy
plt.plot(history.history[&#39;acc&#39;])
plt.plot(history.history[&#39;val_acc&#39;])
plt.title(&#39;model accuracy&#39;)
plt.ylabel(&#39;accuracy&#39;)
plt.xlabel(&#39;epoch&#39;)
plt.legend([&#39;train&#39;, &#39;test&#39;], loc=&#39;upper left&#39;)
plt.show()
# summarize history for loss
plt.plot(history.history[&#39;loss&#39;])
plt.plot(history.history[&#39;val_loss&#39;])
plt.title(&#39;model loss&#39;)
plt.ylabel(&#39;loss&#39;)
plt.xlabel(&#39;epoch&#39;)
plt.legend([&#39;train&#39;, &#39;test&#39;], loc=&#39;upper left&#39;)
plt.show()

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;acc: 80.08%
Saved model to disk
dict_keys([&#39;val_acc&#39;, &#39;val_loss&#39;, &#39;loss&#39;, &#39;acc&#39;])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ten2net.github.io/post/index-readme_files/index-readme_4_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ten2net.github.io/post/index-readme_files/index-readme_4_2.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;使用正则化和dropout&#34;&gt;使用正则化和Dropout&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
from matplotlib import pyplot as plt

from keras.models import Sequential
from keras.layers import Dense,Dropout,Activation
from keras.models import model_from_json
import numpy
import os
#正则化
# import BatchNormalization
from keras.layers.normalization import BatchNormalization

# 为了多次执行再现结果，这只一个固定的随机数   fix random seed for reproducibility
seed = 7
numpy.random.seed(seed)
# 加载数据集 load pima indians dataset
dataset = numpy.loadtxt(&amp;quot;pima-indians-diabetes.csv&amp;quot;, delimiter=&amp;quot;,&amp;quot;)
# 分开数据集为输入和输出两部分  split into input (X) and output (Y) variables
X = dataset[:,0:8]
Y = dataset[:,8]

# 创建模型 create model
model = Sequential()
model.add(Dense(12, input_dim=8, init=&#39;uniform&#39;))
model.add(BatchNormalization())
model.add(Activation(&#39;relu&#39;))
model.add(Dropout(0.5))

model.add(Dense(8, init=&#39;uniform&#39;))
model.add(BatchNormalization())
model.add(Activation(&#39;relu&#39;))
model.add(Dropout(0.5))

model.add(Dense(1, init=&#39;uniform&#39;))
model.add(BatchNormalization())
model.add(Activation(&#39;sigmoid&#39;))

# 编译模型 Compile model
model.compile(loss=&#39;binary_crossentropy&#39;, optimizer=&#39;adam&#39;, metrics=[&#39;accuracy&#39;])
# 训练模型  Fit the model
history= model.fit(X, Y,validation_split=0.25, nb_epoch=300, batch_size=10, verbose=0)

# 评估模型 evaluate the model
scores = model.evaluate(X, Y, verbose=0)
print(&amp;quot;%s: %.2f%%&amp;quot; % (model.metrics_names[1], scores[1]*100))
 
# 保存模型 serialize model to JSON
model_json = model.to_json()
with open(&amp;quot;./models/diabetes-model.json&amp;quot;, &amp;quot;w&amp;quot;) as json_file:
    json_file.write(model_json)
# 保存权重 serialize weights to HDF5
model.save_weights(&amp;quot;./models/diabetes-model.h5&amp;quot;)
print(&amp;quot;Saved model to disk&amp;quot;)

#训练过程可视化
# list all data in history
print(history.history.keys())
# summarize history for accuracy
plt.plot(history.history[&#39;acc&#39;])
plt.plot(history.history[&#39;val_acc&#39;])
plt.title(&#39;model accuracy&#39;)
plt.ylabel(&#39;accuracy&#39;)
plt.xlabel(&#39;epoch&#39;)
plt.legend([&#39;train&#39;, &#39;test&#39;], loc=&#39;upper left&#39;)
plt.show()
# summarize history for loss
plt.plot(history.history[&#39;loss&#39;])
plt.plot(history.history[&#39;val_loss&#39;])
plt.title(&#39;model loss&#39;)
plt.ylabel(&#39;loss&#39;)
plt.xlabel(&#39;epoch&#39;)
plt.legend([&#39;train&#39;, &#39;test&#39;], loc=&#39;upper left&#39;)
plt.show()

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;acc: 76.69%
Saved model to disk
dict_keys([&#39;val_acc&#39;, &#39;val_loss&#39;, &#39;loss&#39;, &#39;acc&#39;])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ten2net.github.io/post/index-readme_files/index-readme_6_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ten2net.github.io/post/index-readme_files/index-readme_6_2.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;使用sgd优化器&#34;&gt;使用SGD优化器&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
from matplotlib import pyplot as plt

from keras.models import Sequential
from keras.optimizers import SGD
from keras.layers import Dense,Dropout,Activation
from keras.models import model_from_json
import numpy
import os
#正则化
# import BatchNormalization
from keras.layers.normalization import BatchNormalization

# 为了多次执行再现结果，这只一个固定的随机数   fix random seed for reproducibility
seed = 7
numpy.random.seed(seed)
# 加载数据集 load pima indians dataset
dataset = numpy.loadtxt(&amp;quot;pima-indians-diabetes.csv&amp;quot;, delimiter=&amp;quot;,&amp;quot;)
# 分开数据集为输入和输出两部分  split into input (X) and output (Y) variables
X = dataset[:,0:8]
Y = dataset[:,8]

# 创建模型 create model
model = Sequential()
model.add(Dense(12, input_dim=8, init=&#39;uniform&#39;))
model.add(BatchNormalization())
model.add(Activation(&#39;relu&#39;))
model.add(Dropout(0.5))

model.add(Dense(8, init=&#39;uniform&#39;))
model.add(BatchNormalization())
model.add(Activation(&#39;relu&#39;))
model.add(Dropout(0.5))

model.add(Dense(1, init=&#39;uniform&#39;))
model.add(BatchNormalization())
model.add(Activation(&#39;sigmoid&#39;))

# 编译模型 Compile model
sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss=&#39;binary_crossentropy&#39;, optimizer=sgd, metrics=[&#39;accuracy&#39;])
# 训练模型  Fit the model
history= model.fit(X, Y,validation_split=0.25, nb_epoch=300, batch_size=10, verbose=0)

# 评估模型 evaluate the model
scores = model.evaluate(X, Y, verbose=0)
print(&amp;quot;%s: %.2f%%&amp;quot; % (model.metrics_names[1], scores[1]*100))
 
# 保存模型 serialize model to JSON
model_json = model.to_json()
with open(&amp;quot;./models/diabetes-model.json&amp;quot;, &amp;quot;w&amp;quot;) as json_file:
    json_file.write(model_json)
# 保存权重 serialize weights to HDF5
model.save_weights(&amp;quot;./models/diabetes-model.h5&amp;quot;)
print(&amp;quot;Saved model to disk&amp;quot;)

#训练过程可视化
# list all data in history
print(history.history.keys())
# summarize history for accuracy
plt.plot(history.history[&#39;acc&#39;])
plt.plot(history.history[&#39;val_acc&#39;])
plt.title(&#39;model accuracy&#39;)
plt.ylabel(&#39;accuracy&#39;)
plt.xlabel(&#39;epoch&#39;)
plt.legend([&#39;train&#39;, &#39;test&#39;], loc=&#39;upper left&#39;)
plt.show()
# summarize history for loss
plt.plot(history.history[&#39;loss&#39;])
plt.plot(history.history[&#39;val_loss&#39;])
plt.title(&#39;model loss&#39;)
plt.ylabel(&#39;loss&#39;)
plt.xlabel(&#39;epoch&#39;)
plt.legend([&#39;train&#39;, &#39;test&#39;], loc=&#39;upper left&#39;)
plt.show()

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;acc: 76.69%
Saved model to disk
dict_keys([&#39;val_acc&#39;, &#39;val_loss&#39;, &#39;loss&#39;, &#39;acc&#39;])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ten2net.github.io/post/index-readme_files/index-readme_8_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ten2net.github.io/post/index-readme_files/index-readme_8_2.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
from matplotlib import pyplot as plt
from keras.callbacks import EarlyStopping,ModelCheckpoint
from keras.models import Sequential
from keras.layers import Dense,Dropout
from keras.models import model_from_json
import numpy as np
import os
# 为了多次执行再现结果，这只一个固定的随机数   fix random seed for reproducibility
seed = 7
np.random.seed(seed)
# 加载数据集 load pima indians dataset
dataset = numpy.loadtxt(&amp;quot;pima-indians-diabetes.csv&amp;quot;, delimiter=&amp;quot;,&amp;quot;)
# 分开数据集为输入和输出两部分  split into input (X) and output (Y) variables
X = dataset[:,0:8]
Y = dataset[:,8]

# 创建模型 create model
model = Sequential()
model.add(Dense(12, input_dim=8, init=&#39;uniform&#39;, activation=&#39;relu&#39;))
model.add(Dense(8, init=&#39;uniform&#39;, activation=&#39;relu&#39;))
model.add(Dense(1, init=&#39;uniform&#39;, activation=&#39;sigmoid&#39;))
# 编译模型 Compile model
model.compile(loss=&#39;binary_crossentropy&#39;, optimizer=&#39;adam&#39;, metrics=[&#39;accuracy&#39;])

#--早停 和检查点-callback---
filepath=&amp;quot;./temp/diabetes-weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5&amp;quot;
checkpoint = ModelCheckpoint(filepath, monitor=&#39;val_acc&#39;, verbose=1, save_best_only=True, mode=&#39;max&#39;)
checkpoint2=ModelCheckpoint(&amp;quot;./temp/diabetes-weights.{epoch:02d}-{val_loss:.2f}.h5&amp;quot;, monitor=&#39;val_loss&#39;, verbose=0, save_best_only=False, mode=&#39;auto&#39;)
#当监测值不再改善时，该回调函数将中止训练
   # patience：当early stop被激活（如发现loss相比上一个epoch训练没有下降），
    # 则经过patience个epoch后停止训练。
estop = EarlyStopping(monitor=&#39;val_loss&#39;, patience=5, verbose=0, mode=&#39;auto&#39;)
#--------------------------------------

# 训练模型  Fit the model
history= model.fit(X, Y,validation_split=0.5, nb_epoch=150, batch_size=10, verbose=0,callbacks=[checkpoint,checkpoint2,estop])

# 评估模型 evaluate the model
scores = model.evaluate(X, Y, verbose=0)
print(&amp;quot;%s: %.2f%%&amp;quot; % (model.metrics_names[1], scores[1]*100))
 
# 保存模型 serialize model to JSON
model_json = model.to_json()
with open(&amp;quot;./models/diabetes-model.json&amp;quot;, &amp;quot;w&amp;quot;) as json_file:
    json_file.write(model_json)
# 保存权重 serialize weights to HDF5
model.save_weights(&amp;quot;./models/diabetes-model.h5&amp;quot;)
print(&amp;quot;Saved model to disk&amp;quot;)

#训练过程可视化
# list all data in history
print(history.history.keys())
# summarize history for accuracy
plt.plot(history.history[&#39;acc&#39;])
plt.plot(history.history[&#39;val_acc&#39;])
plt.title(&#39;model accuracy&#39;)
plt.ylabel(&#39;accuracy&#39;)
plt.xlabel(&#39;epoch&#39;)
plt.legend([&#39;train&#39;, &#39;test&#39;], loc=&#39;upper left&#39;)
plt.show()
# summarize history for loss
plt.plot(history.history[&#39;loss&#39;])
plt.plot(history.history[&#39;val_loss&#39;])
plt.title(&#39;model loss&#39;)
plt.ylabel(&#39;loss&#39;)
plt.xlabel(&#39;epoch&#39;)
plt.legend([&#39;train&#39;, &#39;test&#39;], loc=&#39;upper left&#39;)
plt.show()

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Epoch 00000: val_acc improved from -inf to 0.68490, saving model to ./temp/diabetes-weights-improvement-00-0.68.hdf5
Epoch 00001: val_acc did not improve
Epoch 00002: val_acc did not improve
Epoch 00003: val_acc did not improve
Epoch 00004: val_acc did not improve
Epoch 00005: val_acc did not improve
Epoch 00006: val_acc improved from 0.68490 to 0.69010, saving model to ./temp/diabetes-weights-improvement-06-0.69.hdf5
Epoch 00007: val_acc did not improve
Epoch 00008: val_acc did not improve
Epoch 00009: val_acc did not improve
Epoch 00010: val_acc did not improve
Epoch 00011: val_acc improved from 0.69010 to 0.69010, saving model to ./temp/diabetes-weights-improvement-11-0.69.hdf5
Epoch 00012: val_acc did not improve
Epoch 00013: val_acc did not improve
Epoch 00014: val_acc did not improve
Epoch 00015: val_acc did not improve
Epoch 00016: val_acc did not improve
Epoch 00017: val_acc did not improve
Epoch 00018: val_acc did not improve
Epoch 00019: val_acc did not improve
Epoch 00020: val_acc did not improve
Epoch 00021: val_acc did not improve
Epoch 00022: val_acc did not improve
Epoch 00023: val_acc did not improve
Epoch 00024: val_acc did not improve
Epoch 00025: val_acc did not improve
Epoch 00026: val_acc did not improve
Epoch 00027: val_acc did not improve
Epoch 00028: val_acc did not improve
Epoch 00029: val_acc did not improve
Epoch 00030: val_acc did not improve
Epoch 00031: val_acc did not improve
acc: 69.01%
Saved model to disk
dict_keys([&#39;val_acc&#39;, &#39;val_loss&#39;, &#39;loss&#39;, &#39;acc&#39;])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ten2net.github.io/post/index-readme_files/index-readme_9_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ten2net.github.io/post/index-readme_files/index-readme_9_2.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;loss, accuracy = model.evaluate(X_test,Y_test, verbose=0)
predicted_classes = model.predict_classes(X_test)
correct_classified_indices = np.nonzero(predicted_classes == y_test)[0]
incorrect_classified_indices = np.nonzero(predicted_classes != y_test)[0]
correct_classified_indices
array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 14, 15, 16])
incorrect_classified_indices
array([ 0, 13])
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>使用digits进行finetune</title>
      <link>https://ten2net.github.io/2016/12/21/%E4%BD%BF%E7%94%A8digits%E8%BF%9B%E8%A1%8Cfinetune/</link>
      <pubDate>Wed, 21 Dec 2016 17:45:00 +0800</pubDate>
      <author>wangf@e-u.cn (wangf)</author>
      <guid>https://ten2net.github.io/2016/12/21/%E4%BD%BF%E7%94%A8digits%E8%BF%9B%E8%A1%8Cfinetune/</guid>
      <description>

&lt;h1 id=&#34;一-下载model参数&#34;&gt;一、下载model参数&lt;/h1&gt;

&lt;p&gt;可以直接在浏览器里输入地址下载，也可以运行脚本文件下载。下载地址为：&lt;a href=&#34;http://dl.caffe.berkeleyvision.org/bvlc_reference_caffenet.caffemodel&#34;&gt;http://dl.caffe.berkeleyvision.org/bvlc_reference_caffenet.caffemodel&lt;/a&gt;
文件名称为：bvlc_reference_caffenet.caffemodel，文件大小为230M左右，为了代码的统一，将这个caffemodel文件下载到caffe根目录下的 models/bvlc_reference_caffenet/ 文件夹下面。也可以运行脚本文件进行下载：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# sudo ./scripts/download_model_binary.py models/bvlc_reference_caffenet
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;二-准备数据&#34;&gt;二、准备数据&lt;/h1&gt;

&lt;p&gt;将训练数据放在一个文件夹内。比如我在当前用户根目录下创建了一个data文件夹，专门用来存放数据，因此我的训练图片路径为：/home/xxx/data/re/train
打开浏览器，运行digits，新建一个classification dataset,设置如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ten2net.github.io/post/images/digits/image001.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;下面图片格式选为jpg, 为dataset取一个名字，就开始转换吧。结果如图：&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;https://ten2net.github.io/post/images/digits/image003.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;三-设置model&#34;&gt;三、设置model&lt;/h1&gt;

&lt;p&gt;回到digits根目录，新建一个classification model， 选中你的dataset, 开始设置最重要的network.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ten2net.github.io/post/images/digits/image005.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;caffenet的网络配置文件，放在 caffe/models/bvlc_reference_caffenet/ 这个文件夹里面，名字叫train_val.prototxt。打开这个文件，将里面的内容复制到上图的Custom Network文本框里，然后进行修改，主要修改这几个地方：&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;1-修改train阶段的data层为&#34;&gt;1、修改train阶段的data层为：&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;layer {
  name: &amp;quot;data&amp;quot;
  type: &amp;quot;Data&amp;quot;
  top: &amp;quot;data&amp;quot;
  top: &amp;quot;label&amp;quot;
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
  }
}

&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;即把均值文件（mean_file)、数据源文件(source)、批次大小(batch_size)和数据源格式（backend)这四项都删除了。因为这四项系统会根据dataset和页面左边“solver options&amp;raquo;的设置自动生成。如果想用原始数据训练，可以不用crop_size，即图像数据不会crop,按照原始图像大小训练。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;2-修改test阶段的data层-和上面一样-也是删除那些项&#34;&gt;2、修改test阶段的data层：和上面一样，也是删除那些项。&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;layer {
  name: &amp;quot;data&amp;quot;
  type: &amp;quot;Data&amp;quot;
  top: &amp;quot;data&amp;quot;
  top: &amp;quot;label&amp;quot;
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;3-修改最后一个全连接层-fc8&#34;&gt;3、修改最后一个全连接层（fc8)：&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;layer {
  name: &amp;quot;fc8-re&amp;quot;               #原来为&amp;quot;fc8&amp;quot;
  type: &amp;quot;InnerProduct&amp;quot;
  bottom: &amp;quot;fc7&amp;quot;
  top: &amp;quot;fc8&amp;quot;
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 5        #原来为&amp;quot;1000&amp;quot;
    weight_filler {
      type: &amp;quot;gaussian&amp;quot;
      std: 0.01
    }
    bias_filler {
      type: &amp;quot;constant&amp;quot;
      value: 0.0
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;看注释的地方，就只有两个地方修改，其它不变。&lt;/li&gt;
&lt;li&gt;设置好后，就可以开始微调了(fine tuning).&lt;/li&gt;
&lt;li&gt;训练结果就是一个新的model，可以用来单张图片和多张图片测试。在此，将别人训练好的model用到我们自己的图片分类上，整个微调过程就是这样了。如果你不用digits，而直接用命令操作，那就更简单，只需要修改一个train_val.prototxt的配置文件就可以了，其它都是一样的操作。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;【注意】新版digits的网络结构是针对所有网络的，即包括的训练的网络结构，测试的网络结构和验证的网络结构，即在一个.prototxt 中包含了train/val/deploy 所有的结构。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果使用新版digits，除了上面数据层和最后一个全连接层的改动外，还有以下3处：&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;（1）修改accuracy层，删除原来phase: TEST修改为stage: &amp;laquo;val&amp;raquo;，下图的-表示删除，+表示增加，后面的均是这样表示。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;layer {
name: &amp;quot;accuracy&amp;quot;
     type: &amp;quot;Accuracy&amp;quot;
     bottom: &amp;quot;output&amp;quot;
     bottom: &amp;quot;label&amp;quot;
     top: &amp;quot;accuracy&amp;quot;
-     include {
-         phase: TEST
-     }
+    include { stage: &amp;quot;val&amp;quot; }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;（2）修改loss层，增加exclude { stage: &amp;laquo;deploy&amp;raquo; }，表示loss只在训练和验证中计算，测试时不计算。&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;layer {
       name: &amp;quot;loss&amp;quot;
       type: &amp;quot;SoftmaxWithLoss&amp;quot;
       bottom: &amp;quot;output&amp;quot;
       bottom: &amp;quot;label&amp;quot;
       top: &amp;quot;loss&amp;quot;
+     exclude { stage: &amp;quot;deploy&amp;quot; }
+}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;（3）增加softmax层，该层不在训练和验证中计算，只在测试时计算。&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;+ layer {
+      name: &amp;quot;softmax&amp;quot;
+      type: &amp;quot;Softmax&amp;quot;
+      bottom: &amp;quot;output&amp;quot;
+      top: &amp;quot;softmax&amp;quot;
+         include { stage: &amp;quot;deploy&amp;quot; }
+}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Opencv在Ubuntu上的安装过程</title>
      <link>https://ten2net.github.io/2016/12/21/opencv%E5%9C%A8ubuntu%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/</link>
      <pubDate>Wed, 21 Dec 2016 09:52:09 +0800</pubDate>
      <author>wangf@e-u.cn (wangf)</author>
      <guid>https://ten2net.github.io/2016/12/21/opencv%E5%9C%A8ubuntu%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/</guid>
      <description>

&lt;h1 id=&#34;一-阅读-https-www-raben-com-content-opencv-installation-ubuntu-1204&#34;&gt;一、&lt;a href=&#34;https://www.raben.com/content/opencv-installation-ubuntu-1204&#34;&gt;阅读&lt;/a&gt;&lt;/h1&gt;

&lt;h1 id=&#34;二-安装依赖&#34;&gt;二、安装依赖&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;To install OpenCV 2.4.2 or 2.4.3 on the Ubuntu 12.04 operating system, first install a developer environment to build OpenCV.
apt-get -y install build-essential cmake pkg-config&lt;/li&gt;
&lt;li&gt;Install Image I/O libraries
apt-get -y install libjpeg62-dev
apt-get -y install libtiff4-dev libjasper-dev&lt;/li&gt;
&lt;li&gt;Install the GTK dev library
apt-get -y install  libgtk2.0-dev&lt;/li&gt;
&lt;li&gt;Install Video I/O libraries
apt-get -y install libavcodec-dev libavformat-dev libswscale-dev libv4l-dev&lt;/li&gt;
&lt;li&gt;Optional - install support for Firewire video cameras
apt-get -y install libdc1394-22-dev&lt;/li&gt;
&lt;li&gt;Optional - install video streaming libraries
apt-get -y install libxine-dev libgstreamer0.10-dev libgstreamer-plugins-base0.10-dev&lt;/li&gt;
&lt;li&gt;Optional - install the Python development environment and the Python Numerical library
apt-get -y install python-dev python-numpy&lt;/li&gt;
&lt;li&gt;Optional - install the parallel code processing library (the Intel tbb library)
apt-get -y install libtbb-dev&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Optional - install the Qt dev library
apt-get -y install libqt4-dev&lt;/p&gt;

&lt;h1 id=&#34;三-安装opencv&#34;&gt;三、安装opencv&lt;/h1&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;wget &lt;a href=&#34;https://sourceforge.net/projects/opencvlibrary/files/opencv-unix/2.4.13/opencv-2.4.13.zip&#34;&gt;https://sourceforge.net/projects/opencvlibrary/files/opencv-unix/2.4.13/opencv-2.4.13.zip&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;unzip opencv-2.4.13.zip&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;cd opencv-2.4.13&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;#（可选，若出现list_filterout错误）修改samples/gpu/CMakeLists.txt 文件的106、109、110、111、112五行代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;	 if(NOT HAVE_OPENGL)
	 #   list_filterout(install_list &amp;quot;.*opengl.cpp&amp;quot;)
	  endif()
	  if(NOT HAVE_CUDA)
	 #   list_filterout(install_list &amp;quot;.*opticalflow_nvidia_api.cpp&amp;quot;)
	 #   list_filterout(install_list &amp;quot;.*cascadeclassifier_nvidia_api.cpp&amp;quot;)
	 #   list_filterout(install_list &amp;quot;.*driver_api_multi.cpp&amp;quot;)
	 #   list_filterout(install_list &amp;quot;.*driver_api_stereo_multi.cpp&amp;quot;)
	  endif()
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;mkdir build&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;cd build&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local  -D WITH_TBB=ON -D BUILD_NEW_PYTHON_SUPPORT=ON -D WITH_V4L=ON -D WITH_FFMPEG=OFF    -D INSTALL_C_EXAMPLES=ON -D INSTALL_PYTHON_EXAMPLES=ON     -D BUILD_EXAMPLES=OFF -D WITH_QT=OFF -D WITH_OPENGL=OFF ..&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;make&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;make install&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;四-问题&#34;&gt;四、问题&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;### 解决1394问题
ln /dev/null /dev/raw1394
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;五-测试&#34;&gt;五、测试&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;python&lt;/li&gt;
&lt;li&gt;&amp;gt;&amp;gt;&amp;gt;import cv2&lt;/li&gt;
&lt;li&gt;不报错即表示安装成功&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;附：安装gnome后出现中文乱码的问题
  apt-get install gnome-language-selector
  然后在Xterm中执行
  #gnome-language-selector&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>