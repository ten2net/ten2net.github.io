<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>学习之心</title>
    <link>https://ten2net.github.io/index.xml</link>
    <description>Recent content on 学习之心</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <managingEditor>wangf@e-u.cn (wangf)</managingEditor>
    <webMaster>wangf@e-u.cn (wangf)</webMaster>
    <copyright>(c) 2017 ten2net 西安长城数字软件有限公司.</copyright>
    <lastBuildDate>Thu, 22 Dec 2016 12:12:19 +0800</lastBuildDate>
    <atom:link href="https://ten2net.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>计算机三维仿真常用软件</title>
      <link>https://ten2net.github.io/2016/12/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%89%E7%BB%B4%E4%BB%BF%E7%9C%9F%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6/</link>
      <pubDate>Thu, 22 Dec 2016 12:12:19 +0800</pubDate>
      <author>wangf@e-u.cn (wangf)</author>
      <guid>https://ten2net.github.io/2016/12/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%89%E7%BB%B4%E4%BB%BF%E7%9C%9F%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6/</guid>
      <description>

&lt;ol&gt;
&lt;li&gt;地图绘制及地形数据处理软件：Global Mapper 16&lt;/li&gt;

&lt;li&gt;&lt;h2 id=&#34;三维交互电子手册制作软件-eon-professional-9-0&#34;&gt;三维交互电子手册制作软件 EON Professional 9.0&lt;/h2&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;加拿大Presagis公司 三维建模软件：Creator 4.2&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;加拿大Presagis公司 地形建模软件：Terra Vista 6.2&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;加拿大Presagis公司 视景仿真软件：Vega Prime 4.1 for VC8&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;h2 id=&#34;美国disti公司-虚拟仪表仿真软件-gl-studio-3-2-for-vc8&#34;&gt;美国DiSTI公司 虚拟仪表仿真软件:GL Studio 3.2  for VC8&lt;/h2&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;美国MAK公司 计算机兵力生成及军事想定编辑与仿真软件：MAK VR_FORCE 3.12.0.2&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;美国MAK公司 实时系统运行支撑软件：MAK_RTI 3.4&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;美国MAK公司 分布式仿真连接软件开发包：VR_LINK 3.11.1&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;美国MAK公司 三维战场态势软件：MAK stealth 6.2 、VR_VANTAGE 1.2.1&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Keras笔记</title>
      <link>https://ten2net.github.io/2016/12/22/keras%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Thu, 22 Dec 2016 11:15:53 +0800</pubDate>
      <author>wangf@e-u.cn (wangf)</author>
      <guid>https://ten2net.github.io/2016/12/22/keras%E7%AC%94%E8%AE%B0/</guid>
      <description>

&lt;h1 id=&#34;如何开始&#34;&gt;如何开始&lt;/h1&gt;

&lt;h2 id=&#34;1-光标移动到下面的-import-keras-cell中&#34;&gt;1、光标移动到下面的 import keras   Cell中；&lt;/h2&gt;

&lt;h2 id=&#34;2-shift-enter或点击上面的运行按钮-类似播放&#34;&gt;2、Shift+Enter或点击上面的运行按钮（类似播放）&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;  出现Using Theano backend.那么Keras就已经成功安装了
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import keras
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#查看mnist数据集
%matplotlib inline
from keras.datasets import mnist
from matplotlib import pyplot as plt
# load data
(X_train, y_train), (X_test, y_test) = mnist.load_data(&amp;quot;/notebook/datasets/mnist.pkl&amp;quot;)
# create a grid of 3x3 images
for i in range(0, 9):
    plt.subplot(330 + 1 + i)
    plt.imshow(X_train[i], cmap=plt.get_cmap(&#39;gray&#39;))
# show the plot
plt.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
from matplotlib import pyplot as plt

from keras.models import Sequential
from keras.layers import Dense,Dropout
from keras.models import model_from_json
import numpy
import os
# 为了多次执行再现结果，这只一个固定的随机数   fix random seed for reproducibility
seed = 7
numpy.random.seed(seed)
# 加载数据集 load pima indians dataset
dataset = numpy.loadtxt(&amp;quot;pima-indians-diabetes.csv&amp;quot;, delimiter=&amp;quot;,&amp;quot;)
# 分开数据集为输入和输出两部分  split into input (X) and output (Y) variables
X = dataset[:,0:8]
Y = dataset[:,8]

print (X.shape,Y.shape)
print (Y)

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;(768, 8) (768,)
[ 1.  0.  1.  0.  1.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  1.  1.  1.
  0.  1.  0.  0.  1.  1.  1.  1.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.
  0.  1.  1.  1.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.
  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.
  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1.  1.  1.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.  0.  0.  1.  1.
  0.  0.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.
  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  0.  0.
  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  1.  0.  1.
  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  1.  1.  0.  1.  0.  1.
  1.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  1.  1.  1.
  1.  0.  1.  1.  1.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.
  0.  1.  1.  1.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.  0.  0.
  0.  0.  1.  1.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.  1.  0.  0.  1.
  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.
  0.  0.  0.  1.  1.  1.  0.  0.  1.  0.  1.  0.  1.  1.  0.  1.  0.  0.
  1.  0.  1.  1.  0.  0.  1.  0.  1.  0.  0.  1.  0.  1.  0.  1.  1.  1.
  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.
  1.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.
  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  1.  0.  1.  1.  0.  1.  0.  1.  0.  1.  0.  1.  1.  0.  0.  0.  0.
  1.  1.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  0.
  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  1.  0.
  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  1.
  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.
  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.
  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.
  1.  1.  1.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.
  0.  1.  0.  1.  1.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  0.  1.  0.
  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.  1.
  1.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  1.
  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.
  1.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.  1.
  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  1.  0.  0.  0.  0.  1.
  1.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.
  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.
  0.  1.  1.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  1.  0.  1.  0.  1.  0.  0.  0.  0.  1.  0.]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
from matplotlib import pyplot as plt

from keras.models import Sequential
from keras.layers import Dense,Dropout
from keras.models import model_from_json
import numpy
import os
# 为了多次执行再现结果，这只一个固定的随机数   fix random seed for reproducibility
seed = 7
numpy.random.seed(seed)
# 加载数据集 load pima indians dataset
dataset = numpy.loadtxt(&amp;quot;pima-indians-diabetes.csv&amp;quot;, delimiter=&amp;quot;,&amp;quot;)
# 分开数据集为输入和输出两部分  split into input (X) and output (Y) variables
X = dataset[:,0:8]
Y = dataset[:,8]

# 创建模型 create model
model = Sequential()
model.add(Dense(12, input_dim=8, init=&#39;uniform&#39;, activation=&#39;relu&#39;))
model.add(Dense(8, init=&#39;uniform&#39;, activation=&#39;relu&#39;))
model.add(Dense(1, init=&#39;uniform&#39;, activation=&#39;sigmoid&#39;))
# 编译模型 Compile model
model.compile(loss=&#39;binary_crossentropy&#39;, optimizer=&#39;adam&#39;, metrics=[&#39;accuracy&#39;])
# 训练模型  Fit the model
history= model.fit(X, Y,validation_split=0.25, nb_epoch=300, batch_size=10, verbose=0)

# 评估模型 evaluate the model
scores = model.evaluate(X, Y, verbose=0)
print(&amp;quot;%s: %.2f%%&amp;quot; % (model.metrics_names[1], scores[1]*100))
 
# 保存模型 serialize model to JSON
model_json = model.to_json()
with open(&amp;quot;./models/diabetes-model.json&amp;quot;, &amp;quot;w&amp;quot;) as json_file:
    json_file.write(model_json)
# 保存权重 serialize weights to HDF5
model.save_weights(&amp;quot;./models/diabetes-model.h5&amp;quot;)
print(&amp;quot;Saved model to disk&amp;quot;)

#训练过程可视化
# list all data in history
print(history.history.keys())
# summarize history for accuracy
plt.plot(history.history[&#39;acc&#39;])
plt.plot(history.history[&#39;val_acc&#39;])
plt.title(&#39;model accuracy&#39;)
plt.ylabel(&#39;accuracy&#39;)
plt.xlabel(&#39;epoch&#39;)
plt.legend([&#39;train&#39;, &#39;test&#39;], loc=&#39;upper left&#39;)
plt.show()
# summarize history for loss
plt.plot(history.history[&#39;loss&#39;])
plt.plot(history.history[&#39;val_loss&#39;])
plt.title(&#39;model loss&#39;)
plt.ylabel(&#39;loss&#39;)
plt.xlabel(&#39;epoch&#39;)
plt.legend([&#39;train&#39;, &#39;test&#39;], loc=&#39;upper left&#39;)
plt.show()

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;acc: 80.08%
Saved model to disk
dict_keys([&#39;val_acc&#39;, &#39;val_loss&#39;, &#39;loss&#39;, &#39;acc&#39;])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;index-readme_files/index-readme_4_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;index-readme_files/index-readme_4_2.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;使用正则化和dropout&#34;&gt;使用正则化和Dropout&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
from matplotlib import pyplot as plt

from keras.models import Sequential
from keras.layers import Dense,Dropout,Activation
from keras.models import model_from_json
import numpy
import os
#正则化
# import BatchNormalization
from keras.layers.normalization import BatchNormalization

# 为了多次执行再现结果，这只一个固定的随机数   fix random seed for reproducibility
seed = 7
numpy.random.seed(seed)
# 加载数据集 load pima indians dataset
dataset = numpy.loadtxt(&amp;quot;pima-indians-diabetes.csv&amp;quot;, delimiter=&amp;quot;,&amp;quot;)
# 分开数据集为输入和输出两部分  split into input (X) and output (Y) variables
X = dataset[:,0:8]
Y = dataset[:,8]

# 创建模型 create model
model = Sequential()
model.add(Dense(12, input_dim=8, init=&#39;uniform&#39;))
model.add(BatchNormalization())
model.add(Activation(&#39;relu&#39;))
model.add(Dropout(0.5))

model.add(Dense(8, init=&#39;uniform&#39;))
model.add(BatchNormalization())
model.add(Activation(&#39;relu&#39;))
model.add(Dropout(0.5))

model.add(Dense(1, init=&#39;uniform&#39;))
model.add(BatchNormalization())
model.add(Activation(&#39;sigmoid&#39;))

# 编译模型 Compile model
model.compile(loss=&#39;binary_crossentropy&#39;, optimizer=&#39;adam&#39;, metrics=[&#39;accuracy&#39;])
# 训练模型  Fit the model
history= model.fit(X, Y,validation_split=0.25, nb_epoch=300, batch_size=10, verbose=0)

# 评估模型 evaluate the model
scores = model.evaluate(X, Y, verbose=0)
print(&amp;quot;%s: %.2f%%&amp;quot; % (model.metrics_names[1], scores[1]*100))
 
# 保存模型 serialize model to JSON
model_json = model.to_json()
with open(&amp;quot;./models/diabetes-model.json&amp;quot;, &amp;quot;w&amp;quot;) as json_file:
    json_file.write(model_json)
# 保存权重 serialize weights to HDF5
model.save_weights(&amp;quot;./models/diabetes-model.h5&amp;quot;)
print(&amp;quot;Saved model to disk&amp;quot;)

#训练过程可视化
# list all data in history
print(history.history.keys())
# summarize history for accuracy
plt.plot(history.history[&#39;acc&#39;])
plt.plot(history.history[&#39;val_acc&#39;])
plt.title(&#39;model accuracy&#39;)
plt.ylabel(&#39;accuracy&#39;)
plt.xlabel(&#39;epoch&#39;)
plt.legend([&#39;train&#39;, &#39;test&#39;], loc=&#39;upper left&#39;)
plt.show()
# summarize history for loss
plt.plot(history.history[&#39;loss&#39;])
plt.plot(history.history[&#39;val_loss&#39;])
plt.title(&#39;model loss&#39;)
plt.ylabel(&#39;loss&#39;)
plt.xlabel(&#39;epoch&#39;)
plt.legend([&#39;train&#39;, &#39;test&#39;], loc=&#39;upper left&#39;)
plt.show()

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;acc: 76.69%
Saved model to disk
dict_keys([&#39;val_acc&#39;, &#39;val_loss&#39;, &#39;loss&#39;, &#39;acc&#39;])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;index-readme_files/index-readme_6_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;index-readme_files/index-readme_6_2.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;使用sgd优化器&#34;&gt;使用SGD优化器&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
from matplotlib import pyplot as plt

from keras.models import Sequential
from keras.optimizers import SGD
from keras.layers import Dense,Dropout,Activation
from keras.models import model_from_json
import numpy
import os
#正则化
# import BatchNormalization
from keras.layers.normalization import BatchNormalization

# 为了多次执行再现结果，这只一个固定的随机数   fix random seed for reproducibility
seed = 7
numpy.random.seed(seed)
# 加载数据集 load pima indians dataset
dataset = numpy.loadtxt(&amp;quot;pima-indians-diabetes.csv&amp;quot;, delimiter=&amp;quot;,&amp;quot;)
# 分开数据集为输入和输出两部分  split into input (X) and output (Y) variables
X = dataset[:,0:8]
Y = dataset[:,8]

# 创建模型 create model
model = Sequential()
model.add(Dense(12, input_dim=8, init=&#39;uniform&#39;))
model.add(BatchNormalization())
model.add(Activation(&#39;relu&#39;))
model.add(Dropout(0.5))

model.add(Dense(8, init=&#39;uniform&#39;))
model.add(BatchNormalization())
model.add(Activation(&#39;relu&#39;))
model.add(Dropout(0.5))

model.add(Dense(1, init=&#39;uniform&#39;))
model.add(BatchNormalization())
model.add(Activation(&#39;sigmoid&#39;))

# 编译模型 Compile model
sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss=&#39;binary_crossentropy&#39;, optimizer=sgd, metrics=[&#39;accuracy&#39;])
# 训练模型  Fit the model
history= model.fit(X, Y,validation_split=0.25, nb_epoch=300, batch_size=10, verbose=0)

# 评估模型 evaluate the model
scores = model.evaluate(X, Y, verbose=0)
print(&amp;quot;%s: %.2f%%&amp;quot; % (model.metrics_names[1], scores[1]*100))
 
# 保存模型 serialize model to JSON
model_json = model.to_json()
with open(&amp;quot;./models/diabetes-model.json&amp;quot;, &amp;quot;w&amp;quot;) as json_file:
    json_file.write(model_json)
# 保存权重 serialize weights to HDF5
model.save_weights(&amp;quot;./models/diabetes-model.h5&amp;quot;)
print(&amp;quot;Saved model to disk&amp;quot;)

#训练过程可视化
# list all data in history
print(history.history.keys())
# summarize history for accuracy
plt.plot(history.history[&#39;acc&#39;])
plt.plot(history.history[&#39;val_acc&#39;])
plt.title(&#39;model accuracy&#39;)
plt.ylabel(&#39;accuracy&#39;)
plt.xlabel(&#39;epoch&#39;)
plt.legend([&#39;train&#39;, &#39;test&#39;], loc=&#39;upper left&#39;)
plt.show()
# summarize history for loss
plt.plot(history.history[&#39;loss&#39;])
plt.plot(history.history[&#39;val_loss&#39;])
plt.title(&#39;model loss&#39;)
plt.ylabel(&#39;loss&#39;)
plt.xlabel(&#39;epoch&#39;)
plt.legend([&#39;train&#39;, &#39;test&#39;], loc=&#39;upper left&#39;)
plt.show()

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;acc: 76.69%
Saved model to disk
dict_keys([&#39;val_acc&#39;, &#39;val_loss&#39;, &#39;loss&#39;, &#39;acc&#39;])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;index-readme_files/index-readme_8_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;index-readme_files/index-readme_8_2.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
from matplotlib import pyplot as plt
from keras.callbacks import EarlyStopping,ModelCheckpoint
from keras.models import Sequential
from keras.layers import Dense,Dropout
from keras.models import model_from_json
import numpy as np
import os
# 为了多次执行再现结果，这只一个固定的随机数   fix random seed for reproducibility
seed = 7
np.random.seed(seed)
# 加载数据集 load pima indians dataset
dataset = numpy.loadtxt(&amp;quot;pima-indians-diabetes.csv&amp;quot;, delimiter=&amp;quot;,&amp;quot;)
# 分开数据集为输入和输出两部分  split into input (X) and output (Y) variables
X = dataset[:,0:8]
Y = dataset[:,8]

# 创建模型 create model
model = Sequential()
model.add(Dense(12, input_dim=8, init=&#39;uniform&#39;, activation=&#39;relu&#39;))
model.add(Dense(8, init=&#39;uniform&#39;, activation=&#39;relu&#39;))
model.add(Dense(1, init=&#39;uniform&#39;, activation=&#39;sigmoid&#39;))
# 编译模型 Compile model
model.compile(loss=&#39;binary_crossentropy&#39;, optimizer=&#39;adam&#39;, metrics=[&#39;accuracy&#39;])

#--早停 和检查点-callback---
filepath=&amp;quot;./temp/diabetes-weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5&amp;quot;
checkpoint = ModelCheckpoint(filepath, monitor=&#39;val_acc&#39;, verbose=1, save_best_only=True, mode=&#39;max&#39;)
checkpoint2=ModelCheckpoint(&amp;quot;./temp/diabetes-weights.{epoch:02d}-{val_loss:.2f}.h5&amp;quot;, monitor=&#39;val_loss&#39;, verbose=0, save_best_only=False, mode=&#39;auto&#39;)
#当监测值不再改善时，该回调函数将中止训练
   # patience：当early stop被激活（如发现loss相比上一个epoch训练没有下降），
    # 则经过patience个epoch后停止训练。
estop = EarlyStopping(monitor=&#39;val_loss&#39;, patience=5, verbose=0, mode=&#39;auto&#39;)
#--------------------------------------

# 训练模型  Fit the model
history= model.fit(X, Y,validation_split=0.5, nb_epoch=150, batch_size=10, verbose=0,callbacks=[checkpoint,checkpoint2,estop])

# 评估模型 evaluate the model
scores = model.evaluate(X, Y, verbose=0)
print(&amp;quot;%s: %.2f%%&amp;quot; % (model.metrics_names[1], scores[1]*100))
 
# 保存模型 serialize model to JSON
model_json = model.to_json()
with open(&amp;quot;./models/diabetes-model.json&amp;quot;, &amp;quot;w&amp;quot;) as json_file:
    json_file.write(model_json)
# 保存权重 serialize weights to HDF5
model.save_weights(&amp;quot;./models/diabetes-model.h5&amp;quot;)
print(&amp;quot;Saved model to disk&amp;quot;)

#训练过程可视化
# list all data in history
print(history.history.keys())
# summarize history for accuracy
plt.plot(history.history[&#39;acc&#39;])
plt.plot(history.history[&#39;val_acc&#39;])
plt.title(&#39;model accuracy&#39;)
plt.ylabel(&#39;accuracy&#39;)
plt.xlabel(&#39;epoch&#39;)
plt.legend([&#39;train&#39;, &#39;test&#39;], loc=&#39;upper left&#39;)
plt.show()
# summarize history for loss
plt.plot(history.history[&#39;loss&#39;])
plt.plot(history.history[&#39;val_loss&#39;])
plt.title(&#39;model loss&#39;)
plt.ylabel(&#39;loss&#39;)
plt.xlabel(&#39;epoch&#39;)
plt.legend([&#39;train&#39;, &#39;test&#39;], loc=&#39;upper left&#39;)
plt.show()

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Epoch 00000: val_acc improved from -inf to 0.68490, saving model to ./temp/diabetes-weights-improvement-00-0.68.hdf5
Epoch 00001: val_acc did not improve
Epoch 00002: val_acc did not improve
Epoch 00003: val_acc did not improve
Epoch 00004: val_acc did not improve
Epoch 00005: val_acc did not improve
Epoch 00006: val_acc improved from 0.68490 to 0.69010, saving model to ./temp/diabetes-weights-improvement-06-0.69.hdf5
Epoch 00007: val_acc did not improve
Epoch 00008: val_acc did not improve
Epoch 00009: val_acc did not improve
Epoch 00010: val_acc did not improve
Epoch 00011: val_acc improved from 0.69010 to 0.69010, saving model to ./temp/diabetes-weights-improvement-11-0.69.hdf5
Epoch 00012: val_acc did not improve
Epoch 00013: val_acc did not improve
Epoch 00014: val_acc did not improve
Epoch 00015: val_acc did not improve
Epoch 00016: val_acc did not improve
Epoch 00017: val_acc did not improve
Epoch 00018: val_acc did not improve
Epoch 00019: val_acc did not improve
Epoch 00020: val_acc did not improve
Epoch 00021: val_acc did not improve
Epoch 00022: val_acc did not improve
Epoch 00023: val_acc did not improve
Epoch 00024: val_acc did not improve
Epoch 00025: val_acc did not improve
Epoch 00026: val_acc did not improve
Epoch 00027: val_acc did not improve
Epoch 00028: val_acc did not improve
Epoch 00029: val_acc did not improve
Epoch 00030: val_acc did not improve
Epoch 00031: val_acc did not improve
acc: 69.01%
Saved model to disk
dict_keys([&#39;val_acc&#39;, &#39;val_loss&#39;, &#39;loss&#39;, &#39;acc&#39;])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;index-readme_files/index-readme_9_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;index-readme_files/index-readme_9_2.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;loss, accuracy = model.evaluate(X_test,Y_test, verbose=0)
predicted_classes = model.predict_classes(X_test)
correct_classified_indices = np.nonzero(predicted_classes == y_test)[0]
incorrect_classified_indices = np.nonzero(predicted_classes != y_test)[0]
correct_classified_indices
array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 14, 15, 16])
incorrect_classified_indices
array([ 0, 13])
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>我的docker笔记</title>
      <link>https://ten2net.github.io/2016/12/22/%E6%88%91%E7%9A%84docker%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Thu, 22 Dec 2016 11:15:53 +0800</pubDate>
      <author>wangf@e-u.cn (wangf)</author>
      <guid>https://ten2net.github.io/2016/12/22/%E6%88%91%E7%9A%84docker%E7%AC%94%E8%AE%B0/</guid>
      <description>

&lt;h1 id=&#34;1-docker命令基础练习&#34;&gt;1 Docker命令基础练习&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker info
docker images
docker ps
docker version
docker run hello-world
docker pull busybox
docker exec -it busybox /bin/bash

docker run -d -p 80:80 --name webserver nginx
docker run -it alpine env
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;2-dockerfile使用范例&#34;&gt;2 Dockerfile使用范例&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;FROM tomcat
ADD helloworld.war /usr/local/tomcat/webapps/
EXPOSE 8080
CMD [&amp;quot;catalina.sh&amp;quot;, &amp;quot;run&amp;quot;]


docker build -t mytomcat .
docker run -d -p 9280:8080 mytomcat2
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;3-使用-docker-7-个命令部署一个-mesos-集群&#34;&gt;3 使用 Docker， 7 个命令部署一个 Mesos 集群&lt;/h1&gt;

&lt;p&gt;参考：&lt;a href=&#34;https://segmentfault.com/a/1190000002531072&#34;&gt;https://segmentfault.com/a/1190000002531072&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
第一步：或者 Docker 服务器的 IP 并导出到环境变量。我们将在随后的 Docker 命令中不断地使用这个 IP。
set HOST_IP=10.11.31.7
第二步：启动 ZooKeeper 容器
docker run -d -p 2181:2181 -p 2888:2888 -p 3888:3888 garland/zookeeper
第三步：启动 Mesos Master
docker run --net=&amp;quot;host&amp;quot; -p 5050:5050 -e &amp;quot;MESOS_HOSTNAME=${HOST_IP}&amp;quot; -e &amp;quot;MESOS_IP=${HOST_IP}&amp;quot; -e &amp;quot;MESOS_ZK=zk://${HOST_IP}:2181/mesos&amp;quot; -e &amp;quot;MESOS_PORT=5050&amp;quot; -e &amp;quot;MESOS_LOG_DIR=/var/log/mesos&amp;quot; -e &amp;quot;MESOS_QUORUM=1&amp;quot; -e &amp;quot;MESOS_REGISTRY=in_memory&amp;quot; -e &amp;quot;MESOS_WORK_DIR=/var/lib/mesos&amp;quot; -d garland/mesosphere-docker-mesos-master
第四步：启动 Marathon
docker run -d -p 8180:8180 garland/mesosphere-docker-marathon --master zk://${HOST_IP}:2181/mesos --zk zk://${HOST_IP}:2181/marathon
第五步：在一个容器中启动 Mesos Slave
docker run -d --name mesos_slave_1 --entrypoint=&amp;quot;mesos-slave&amp;quot; -e &amp;quot;MESOS_MASTER=zk://${HOST_IP}:2181/mesos&amp;quot; -e &amp;quot;MESOS_LOG_DIR=/var/log/mesos&amp;quot; -e &amp;quot;MESOS_LOGGING_LEVEL=INFO&amp;quot; garland/mesosphere-docker-mesos-master:latest
第六步：进入 Mesos 的 webpage
http://${HOST_IP}:5050
第七步：进入 Marathon 的 webpage 启动一个任务
http://${HOST_IP}:8080
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;4-使用docker-加速器&#34;&gt;4 使用Docker 加速器&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;echo &amp;quot;DOCKER_OPTS=\&amp;quot;\$DOCKER_OPTS --registry-mirror=https://z5sa40yd.mirror.aliyuncs.com\&amp;quot;&amp;quot; | sudo tee -a /etc/default/docker sudo service docker restart
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;阿里云-我的专属加速器地址：&lt;a href=&#34;https://z5sa40yd.mirror.aliyuncs.com&#34;&gt;https://z5sa40yd.mirror.aliyuncs.com&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;这个命令的用法忘记了&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker-machine create --virtualbox-no-vtx-check --engine-registry-mirror=https://z5sa40yd.mirror.aliyuncs.com -d virtualbox default
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;5-ui-for-docker-可视化管理docker的工具&#34;&gt;5 ui-for-docker，可视化管理Docker的工具&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Quickstart ：&lt;a href=&#34;https://github.com/kevana/ui-for-docker&#34;&gt;https://github.com/kevana/ui-for-docker&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt; docker run -d -p 9000:9000 --privileged -v /var/run/docker.sock:/var/run/docker.sock uifd/ui-for-docker
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Open your browser to http://&lt;your Host IP&gt;:9000&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;6-docker-run-命令的常用选项说明&#34;&gt;6 Docker Run 命令的常用选项说明&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;你的Container会在你结束命令之后自动退出，使用以下的命令选项可以将容器保持在激活状态：&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;-i 即使在没有附着的情况下依然保持STDIN处于开启
-t 分配一个伪TTY控制台&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;所以run命令就变成了：
&lt;code&gt;
docker run -it -d shykes/pybuilder bin/bash
&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Docker Exec 命令可以执行正在运行的Docker容器中的Shell命令&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;如果希望能够附着到一个已经存在的容器中，则利用exec命令：&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;docker exec -it CONTAINER_ID bash
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;7-常见的docker命令行命令进行详细介绍&#34;&gt;7 常见的Docker命令行命令进行详细介绍&lt;/h1&gt;

&lt;h2 id=&#34;7-1-与容器-container-相关的命令&#34;&gt;7.1 与容器（Container）相关的命令&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;docker create 会创建一个容器但是不会立刻启动&lt;/li&gt;
&lt;li&gt;docker run 会创建并且启动某个容器&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果只是希望有一个暂时性的容器，可以使用 docker run &amp;ndash;rm 将会在容器运行完毕之后删除该容器。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果希望在打开某个容器之后能够与其进行交互, docker run -t -i  会创建一个TTY控制台。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;docker stop 会关闭某个容器&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;docker start 会启动某个容器&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;docker restart 会重新启动某个容器&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;docker rm 会删除某个容器&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果希望能够移除所有与该容器相关的Volume，可以使用-v参数： docker rm -v.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;docker kill 会发送SIGKILL信号量到某个容器&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;docker attach 会附着到某个正在运行的容器&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;docker wait 会阻塞直到某个容器关闭&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;7-2-与镜像-image-相关的命令&#34;&gt;7.2 与镜像（Image）相关的命令&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;docker images 会展示所有的镜像&lt;/li&gt;
&lt;li&gt;docker import 会从原始码中创建镜像&lt;/li&gt;
&lt;li&gt;docker build 会从某个Dockfile中创建镜像&lt;/li&gt;
&lt;li&gt;docker commit 会从某个Container中创建镜像&lt;/li&gt;
&lt;li&gt;docker rmi 会移除某个镜像&lt;/li&gt;
&lt;li&gt;docker load 以STDIN的方式从某个tar包中加载镜像&lt;/li&gt;
&lt;li&gt;docker save 以STDOUT的方式将镜像存入到某个tar包中&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;7-3-查看docker容器状态信息的命令&#34;&gt;7.3 查看Docker容器状态信息的命令&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;docker ps 会列举出所有正在运行的容器&lt;/li&gt;
&lt;li&gt;docker ps -a 会展示出所有正在运行的和已经停止的容器&lt;/li&gt;
&lt;li&gt;docker logs 从某个容器中获取log日志&lt;/li&gt;
&lt;li&gt;docker inspect 检测关于某个容器的详细信息&lt;/li&gt;
&lt;li&gt;docker events 从某个容器中获取所有的事件&lt;/li&gt;
&lt;li&gt;docker port 获取某个容器的全部的开放端口&lt;/li&gt;
&lt;li&gt;docker top 展示某个容器中运行的全部的进程&lt;/li&gt;
&lt;li&gt;docker stats 展示某个容器中的资源的使用情况的统计信息&lt;/li&gt;
&lt;li&gt;docker diff 展示容器中文件的变化情况&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;7-4-查看docker镜像-image-状态信息的命令&#34;&gt;7.4 查看Docker镜像（Image）状态信息的命令&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;docker history 展示镜像的全部历史信息&lt;/li&gt;
&lt;li&gt;docker tag 为某个容器设置标签&lt;/li&gt;
&lt;li&gt;Import&amp;amp;Export&lt;/li&gt;
&lt;li&gt;docker cp 在容器与本地文件系统之间进行文件复制&lt;/li&gt;
&lt;li&gt;docker export 将某个容器中的文件系统的内容输出到某个tar文件中&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;8-实验machine-learning-过程中练习的命令&#34;&gt;8 实验Machine Learning 过程中练习的命令&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;docker run  ermaker/keras&lt;/li&gt;

&lt;li&gt;&lt;p&gt;docker run -d -p 8888:8888 -e KERAS_BACKEND=tensorflow ermaker/keras-jupyter&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;docker run -d -p 8888:8888 &amp;ndash;name keraslearning  &amp;ndash;restart=always  -v /notebook:/notebook ermaker/keras-jupyter&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;docker run -d -p 8888:8888 &amp;ndash;name keraslearning   &amp;ndash;restart=always -v E:/python-dev-home:/notebook ermaker/keras-jupyter&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;docker run -d -p 8888:8888 &amp;ndash;name keraslearning &amp;ndash;restart=always -v E:/python-dev-home:/notebook ermaker/keras-jupyter&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;nvidia-docker run  -d -p 5001:5000 -v /dataOne:/opt &amp;ndash;name digits &amp;ndash;restart=always  kaixhin/cuda-digits:8.0&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;9-其它常用命令&#34;&gt;9 其它常用命令&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;    # 像Docker官方的hello world例子一样，拉取一个叫busybox的镜像
    docker pull busybox
    
    #进入容器bash
    docker exec -i keraslearning bash

    # 查看本地已经有哪些镜像
    # 我们可以看到busybox
    docker images

    # 现在让我们来修改下busybox镜像的容器
    # 这次，我们创建一个文件夹
    docker run busybox mkdir /home/test


    #从容器keraslearning中复制/notebook目录到当前目录
    docker cp keraslearning:/notebook .

    #从当前目录复制test子目录到容器keraslearning中/notebook目录下
    docker cp test keraslearning:/notebook

    # 让我们再看看我们有哪些镜像了。
    # 注意每条命令执行后容器都会停止
    # 可以看到有一个busybox容器
    docker ps -a

    # 现在，可以提交修改了。
    # 提交后会看到一个新的镜像busybox-1
    #  &amp;lt;CONTAINER ID&amp;gt; 是刚刚修改容器后得到的ID
    docker commit &amp;lt;CONTAINER ID&amp;gt; busybox-1

    # 再看看我们有哪些镜像。
    # 我们现在同时有busybox和busybox-1镜像了。
    docker images

    # 我们执行以下命令，看看这两个镜像有什么不同
    docker run busybox [ -d /home/test ] &amp;amp;&amp;amp; echo &#39;Directory found&#39; || echo &#39;Directory not found&#39;
    docker run busybox-1 [ -d /home/test ] &amp;amp;&amp;amp; echo &#39;Directory found&#39; || echo &#39;Directory not found&#39;


    # 查看所有的容器
    docker ps -a

    # 删除它们
    docker rm &amp;lt;CONTAINER ID&amp;gt;

    # 查看所有的镜像
    docker images

    # 删除它们
    docker rmi busybox-1
    docker rmi busybox

    注：可以使用 docker rm $(docker ps -q -a) 一次性删除所有的容器，docker rmi $(docker images -q) 一次性删除所有的镜像。

    #导出容器
    docker export &amp;lt;CONTAINER ID&amp;gt; -o containers/export123.tar

    #导出镜像
    docker save -o gds-keras-jupyter.tar gds/keraslearning

    #快照容器的当前状态为一个镜像
    docker commit 0d8facbc75e2 gds/keraslearning


    现在我们创建了两个Tar文件，让我们来看看它们是什么。首先做一下小清理——把所有的容器和镜像都删除：

    # 查看所有的容器
    sudo docker ps -a

    # 删除它们
    sudo docker rm &amp;lt;CONTAINER ID&amp;gt;

    # 查看所有的镜像
    sudo docker images

    # 删除它们
    sudo docker rmi busybox-1
    sudo docker rmi busybox
    注：可以使用 docker rm $(docker ps -q -a) 一次性删除所有的容器，docker rmi $(docker images -q) 一次性删除所有的镜像。

    现在开始导入刚刚导出的容器：

    # 导入export.tar文件
    cat /home/export.tar | sudo docker import - busybox-1-export:latest

    # 查看镜像
    sudo docker images

    # 检查是否导入成功，就是启动一个新容器，检查里面是否存在/home/test目录（是存在的）
    sudo docker run busybox-1-export [ -d /home/test ] &amp;amp;&amp;amp; echo &#39;Directory found&#39; || echo &#39;Directory not found&#39;
    使用类似的步骤导入镜像：

    # 导入save.tar文件
    docker load &amp;lt; /home/save.tar
    docker load -i /home/save.tar

    # 查看镜像
    sudo docker images

    # 检查是否导入成功，就是启动一个新容器，检查里面是否存在/home/test目录（是存在的）
    sudo docker run busybox-1 [ -d /home/test ] &amp;amp;&amp;amp; echo &#39;Directory found&#39; || echo &#39;Directory not found&#39;
    那，它们之间到底存在什么不同呢？我们发现导出后的版本会比原来的版本稍微小一些。那是因为导出后，会丢失历史和元数据。执行下面的命令就知道了：

    # 显示镜像的所有层(layer)
    sudo docker images --tree
     执行命令，显示下面的内容。正你看到的，导出后再导入(exported-imported)的镜像会丢失所有的历史，而保存后再加载（saveed-loaded）的镜像没有丢失历史和层(layer)。这意味着使用导出后再导入的方式，你将无法回滚到之前的层(layer)，同时，使用保存后再加载的方式持久化整个镜像，就可以做到层回滚（可以执行docker tag &amp;lt;LAYER ID&amp;gt; &amp;lt;IMAGE NAME&amp;gt;来回滚之前的层）。

    sudo docker images --tree
    ├─f502877df6a1 Virtual Size: 2.489 MB Tags: busybox-1-export:latest
    └─511136ea3c5a Virtual Size: 0 B
      └─bf747efa0e2f Virtual Size: 0 B
        └─48e5f45168b9 Virtual Size: 2.489 MB
          └─769b9341d937 Virtual Size: 2.489 MB
            └─227516d93162 Virtual Size: 2.489 MB Tags: busybox-1:latest

&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>使用digits进行finetune</title>
      <link>https://ten2net.github.io/2016/12/21/%E4%BD%BF%E7%94%A8digits%E8%BF%9B%E8%A1%8Cfinetune/</link>
      <pubDate>Wed, 21 Dec 2016 17:45:00 +0800</pubDate>
      <author>wangf@e-u.cn (wangf)</author>
      <guid>https://ten2net.github.io/2016/12/21/%E4%BD%BF%E7%94%A8digits%E8%BF%9B%E8%A1%8Cfinetune/</guid>
      <description>

&lt;h1 id=&#34;一-下载model参数&#34;&gt;一、下载model参数&lt;/h1&gt;

&lt;p&gt;可以直接在浏览器里输入地址下载，也可以运行脚本文件下载。下载地址为：&lt;a href=&#34;http://dl.caffe.berkeleyvision.org/bvlc_reference_caffenet.caffemodel&#34;&gt;http://dl.caffe.berkeleyvision.org/bvlc_reference_caffenet.caffemodel&lt;/a&gt;
文件名称为：bvlc_reference_caffenet.caffemodel，文件大小为230M左右，为了代码的统一，将这个caffemodel文件下载到caffe根目录下的 models/bvlc_reference_caffenet/ 文件夹下面。也可以运行脚本文件进行下载：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# sudo ./scripts/download_model_binary.py models/bvlc_reference_caffenet
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;二-准备数据&#34;&gt;二、准备数据&lt;/h1&gt;

&lt;p&gt;将训练数据放在一个文件夹内。比如我在当前用户根目录下创建了一个data文件夹，专门用来存放数据，因此我的训练图片路径为：/home/xxx/data/re/train
打开浏览器，运行digits，新建一个classification dataset,设置如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ten2net.github.io/post/images/digits/image001.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;下面图片格式选为jpg, 为dataset取一个名字，就开始转换吧。结果如图：&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;https://ten2net.github.io/post/images/digits/image003.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;三-设置model&#34;&gt;三、设置model&lt;/h1&gt;

&lt;p&gt;回到digits根目录，新建一个classification model， 选中你的dataset, 开始设置最重要的network.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ten2net.github.io/post/images/digits/image005.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;caffenet的网络配置文件，放在 caffe/models/bvlc_reference_caffenet/ 这个文件夹里面，名字叫train_val.prototxt。打开这个文件，将里面的内容复制到上图的Custom Network文本框里，然后进行修改，主要修改这几个地方：&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;1-修改train阶段的data层为&#34;&gt;1、修改train阶段的data层为：&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;layer {
  name: &amp;quot;data&amp;quot;
  type: &amp;quot;Data&amp;quot;
  top: &amp;quot;data&amp;quot;
  top: &amp;quot;label&amp;quot;
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
  }
}

&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;即把均值文件（mean_file)、数据源文件(source)、批次大小(batch_size)和数据源格式（backend)这四项都删除了。因为这四项系统会根据dataset和页面左边“solver options&amp;raquo;的设置自动生成。如果想用原始数据训练，可以不用crop_size，即图像数据不会crop,按照原始图像大小训练。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;2-修改test阶段的data层-和上面一样-也是删除那些项&#34;&gt;2、修改test阶段的data层：和上面一样，也是删除那些项。&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;layer {
  name: &amp;quot;data&amp;quot;
  type: &amp;quot;Data&amp;quot;
  top: &amp;quot;data&amp;quot;
  top: &amp;quot;label&amp;quot;
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;3-修改最后一个全连接层-fc8&#34;&gt;3、修改最后一个全连接层（fc8)：&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;layer {
  name: &amp;quot;fc8-re&amp;quot;               #原来为&amp;quot;fc8&amp;quot;
  type: &amp;quot;InnerProduct&amp;quot;
  bottom: &amp;quot;fc7&amp;quot;
  top: &amp;quot;fc8&amp;quot;
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 5        #原来为&amp;quot;1000&amp;quot;
    weight_filler {
      type: &amp;quot;gaussian&amp;quot;
      std: 0.01
    }
    bias_filler {
      type: &amp;quot;constant&amp;quot;
      value: 0.0
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;看注释的地方，就只有两个地方修改，其它不变。&lt;/li&gt;
&lt;li&gt;设置好后，就可以开始微调了(fine tuning).&lt;/li&gt;
&lt;li&gt;训练结果就是一个新的model，可以用来单张图片和多张图片测试。在此，将别人训练好的model用到我们自己的图片分类上，整个微调过程就是这样了。如果你不用digits，而直接用命令操作，那就更简单，只需要修改一个train_val.prototxt的配置文件就可以了，其它都是一样的操作。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;【注意】新版digits的网络结构是针对所有网络的，即包括的训练的网络结构，测试的网络结构和验证的网络结构，即在一个.prototxt 中包含了train/val/deploy 所有的结构。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果使用新版digits，除了上面数据层和最后一个全连接层的改动外，还有以下3处：&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;（1）修改accuracy层，删除原来phase: TEST修改为stage: &amp;laquo;val&amp;raquo;，下图的-表示删除，+表示增加，后面的均是这样表示。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;layer {
name: &amp;quot;accuracy&amp;quot;
     type: &amp;quot;Accuracy&amp;quot;
     bottom: &amp;quot;output&amp;quot;
     bottom: &amp;quot;label&amp;quot;
     top: &amp;quot;accuracy&amp;quot;
-     include {
-         phase: TEST
-     }
+    include { stage: &amp;quot;val&amp;quot; }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;（2）修改loss层，增加exclude { stage: &amp;laquo;deploy&amp;raquo; }，表示loss只在训练和验证中计算，测试时不计算。&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;layer {
       name: &amp;quot;loss&amp;quot;
       type: &amp;quot;SoftmaxWithLoss&amp;quot;
       bottom: &amp;quot;output&amp;quot;
       bottom: &amp;quot;label&amp;quot;
       top: &amp;quot;loss&amp;quot;
+     exclude { stage: &amp;quot;deploy&amp;quot; }
+}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;（3）增加softmax层，该层不在训练和验证中计算，只在测试时计算。&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;+ layer {
+      name: &amp;quot;softmax&amp;quot;
+      type: &amp;quot;Softmax&amp;quot;
+      bottom: &amp;quot;output&amp;quot;
+      top: &amp;quot;softmax&amp;quot;
+         include { stage: &amp;quot;deploy&amp;quot; }
+}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Opencv在Ubuntu上的安装过程</title>
      <link>https://ten2net.github.io/2016/12/21/opencv%E5%9C%A8ubuntu%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/</link>
      <pubDate>Wed, 21 Dec 2016 09:52:09 +0800</pubDate>
      <author>wangf@e-u.cn (wangf)</author>
      <guid>https://ten2net.github.io/2016/12/21/opencv%E5%9C%A8ubuntu%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/</guid>
      <description>

&lt;h1 id=&#34;一-阅读-https-www-raben-com-content-opencv-installation-ubuntu-1204&#34;&gt;一、&lt;a href=&#34;https://www.raben.com/content/opencv-installation-ubuntu-1204&#34;&gt;阅读&lt;/a&gt;&lt;/h1&gt;

&lt;h1 id=&#34;二-安装依赖&#34;&gt;二、安装依赖&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;To install OpenCV 2.4.2 or 2.4.3 on the Ubuntu 12.04 operating system, first install a developer environment to build OpenCV.
apt-get -y install build-essential cmake pkg-config&lt;/li&gt;
&lt;li&gt;Install Image I/O libraries
apt-get -y install libjpeg62-dev
apt-get -y install libtiff4-dev libjasper-dev&lt;/li&gt;
&lt;li&gt;Install the GTK dev library
apt-get -y install  libgtk2.0-dev&lt;/li&gt;
&lt;li&gt;Install Video I/O libraries
apt-get -y install libavcodec-dev libavformat-dev libswscale-dev libv4l-dev&lt;/li&gt;
&lt;li&gt;Optional - install support for Firewire video cameras
apt-get -y install libdc1394-22-dev&lt;/li&gt;
&lt;li&gt;Optional - install video streaming libraries
apt-get -y install libxine-dev libgstreamer0.10-dev libgstreamer-plugins-base0.10-dev&lt;/li&gt;
&lt;li&gt;Optional - install the Python development environment and the Python Numerical library
apt-get -y install python-dev python-numpy&lt;/li&gt;
&lt;li&gt;Optional - install the parallel code processing library (the Intel tbb library)
apt-get -y install libtbb-dev&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Optional - install the Qt dev library
apt-get -y install libqt4-dev&lt;/p&gt;

&lt;h1 id=&#34;三-安装opencv&#34;&gt;三、安装opencv&lt;/h1&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;wget &lt;a href=&#34;https://sourceforge.net/projects/opencvlibrary/files/opencv-unix/2.4.13/opencv-2.4.13.zip&#34;&gt;https://sourceforge.net/projects/opencvlibrary/files/opencv-unix/2.4.13/opencv-2.4.13.zip&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;unzip opencv-2.4.13.zip&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;cd opencv-2.4.13&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;#（可选，若出现list_filterout错误）修改samples/gpu/CMakeLists.txt 文件的106、109、110、111、112五行代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;	 if(NOT HAVE_OPENGL)
	 #   list_filterout(install_list &amp;quot;.*opengl.cpp&amp;quot;)
	  endif()
	  if(NOT HAVE_CUDA)
	 #   list_filterout(install_list &amp;quot;.*opticalflow_nvidia_api.cpp&amp;quot;)
	 #   list_filterout(install_list &amp;quot;.*cascadeclassifier_nvidia_api.cpp&amp;quot;)
	 #   list_filterout(install_list &amp;quot;.*driver_api_multi.cpp&amp;quot;)
	 #   list_filterout(install_list &amp;quot;.*driver_api_stereo_multi.cpp&amp;quot;)
	  endif()
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;mkdir build&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;cd build&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local  -D WITH_TBB=ON -D BUILD_NEW_PYTHON_SUPPORT=ON -D WITH_V4L=ON -D WITH_FFMPEG=OFF    -D INSTALL_C_EXAMPLES=ON -D INSTALL_PYTHON_EXAMPLES=ON     -D BUILD_EXAMPLES=OFF -D WITH_QT=OFF -D WITH_OPENGL=OFF ..&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;make&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;make install&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;四-问题&#34;&gt;四、问题&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;### 解决1394问题
ln /dev/null /dev/raw1394
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;五-测试&#34;&gt;五、测试&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;python&lt;/li&gt;
&lt;li&gt;&amp;gt;&amp;gt;&amp;gt;import cv2&lt;/li&gt;
&lt;li&gt;不报错即表示安装成功&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;附：安装gnome后出现中文乱码的问题
  apt-get install gnome-language-selector
  然后在Xterm中执行
  #gnome-language-selector&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>